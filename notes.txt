Things to try:

Pass L+1 predictions down, instead of representation
Include in the error signal a second set of channels for delta error
Try including more channels in the input (depth, oFlow), without parallel Prednets
Replace ConvLSTM with other more powerful models
Try custom dataset with moving objects
Include parallel Prednets operating on different data image channels (depth, oFlow)
Add Pan-Hierarchical Predictive Engine
Try different model weights for the different time-steps, at least for the first step, and subsequent steps. The idea is that the first step should bring the representation closely to the previous frame, and subsequent ones should operate on the differences between frames.
think about using FC layers to decode cnn feature maps into more discrete features
    can we do some kind of alternating between cnn and FC?
    what about a binary FC?
    what about an encoded SDR? So, we take the representation activations and enocde them into an SDR that is sensitive to the minute RV variations in the representation tensors. Does this do anything to elucidate the stored information, make it more interpretable? Then this SDR gets passed as the top-down modulation instead of the representation tensor itself.
Can the representation tensors be SDRs with sparse minkowski convolutions? Or rather, can the representations be sparse semantically-encoded HDC vectors and the convLSTM implemented with monkowski engine. I think we need pytorch and to implement the convLSTM manually.