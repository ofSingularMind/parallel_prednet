{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET CONFIGURATION ARGUMENTS\n",
    "\n",
    "args = {\n",
    "    \"nt\": 1,\n",
    "    \"nb_epoch\": 250,\n",
    "    \"batch_size\": 1,\n",
    "    \"output_channels\": [3, 48, 96, 192],\n",
    "    \"num_P_CNN\": 1,\n",
    "    \"num_R_CLSTM\": 1,\n",
    "    \"num_passes\": 1,\n",
    "    \"pan_hierarchical\": False,\n",
    "    \"downscale_factor\": 4,\n",
    "    \"resize_images\": False,\n",
    "    \"train_proportion\": 0.7,\n",
    "    \"results_subdir\": \"dummy\",\n",
    "    \"dataset_weights\": \"SSM\",\n",
    "    \"data_subset_weights\": \"gen_ellipseV_crossH\",\n",
    "    \"dataset\": \"general_shape_static\",\n",
    "    \"data_subset\": \"general_ellipse_static_2nd_stage\",\n",
    "    \"data_subset_mode\": \"test\",\n",
    "    \"model_choice\": \"baseline\",\n",
    "    \"system\": \"laptop\",\n",
    "    \"reserialize_dataset\": False,\n",
    "    \"output_mode\": \"Error\"\n",
    "}\n",
    "args[\"results_subdir\"] = f\"interp_results/{args['dataset']}/{args['data_subset']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "WARNING: dataset (general_shape_static) and dataset_weights (SSM/gen_ellipseV_crossH) do not match - generalizing...\n",
      "Working on dataset: general_shape_static\n",
      "PredNet compiled...\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1, 50, 50, 3)]    0         \n",
      "                                                                 \n",
      " para_pred_net (PredNet  {'Representation_Layer0   6915948   \n",
      " )                           ': (1, 50, 50, 3),                  \n",
      "                              'Prediction_Layer0': (             \n",
      "                             1, 50, 50, 3),                      \n",
      "                              'Representation_Layer1             \n",
      "                             ': (1, 25, 25, 48),                 \n",
      "                              'Prediction_Layer1': (             \n",
      "                             1, 25, 25, 48),                     \n",
      "                              'Representation_Layer2             \n",
      "                             ': (1, 12, 12, 96),                 \n",
      "                              'Prediction_Layer2': (             \n",
      "                             1, 12, 12, 96),                     \n",
      "                              'Representation_Layer3             \n",
      "                             ': (1, 6, 6, 192),                  \n",
      "                              'Prediction_Layer3': (             \n",
      "                             1, 6, 6, 192)}                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6915948 (26.38 MB)\n",
      "Trainable params: 6915948 (26.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "4 PredNet layers with resolutions:\n",
      "Layer 4:  6 x 6 x 192\n",
      "Layer 3:  12 x 12 x 96\n",
      "Layer 2:  25 x 25 x 48\n",
      "Layer 1:  50 x 50 x 3\n",
      "Weights loaded successfully...\n",
      "Test data ready...\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL\n",
    "\n",
    "import argparse\n",
    "from config import update_settings, get_settings\n",
    "from data_utils import serialize_dataset\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "update_settings(args[\"system\"], args[\"dataset_weights\"], args[\"data_subset_weights\"], args[\"results_subdir\"])\n",
    "DATA_DIR, WEIGHTS_DIR, RESULTS_SAVE_DIR, LOG_DIR = get_settings()[\"dirs\"]\n",
    "data_dirs = [DATA_DIR, WEIGHTS_DIR, RESULTS_SAVE_DIR, LOG_DIR]\n",
    "if not os.path.exists(RESULTS_SAVE_DIR):\n",
    "    os.makedirs(RESULTS_SAVE_DIR)\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import hickle as hkl\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# or '2' to filter out INFO messages too\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from data_utils import SequenceGenerator, IntermediateEvaluations, create_dataset_from_serialized_generator, config_gpus \n",
    "%matplotlib tk\n",
    "import matplotlib.pyplot as plt\n",
    "# import addcopyfighandler\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import random\n",
    "\n",
    "# PICK MODEL\n",
    "if args[\"model_choice\"] == \"baseline\":\n",
    "    # Predict next frame along RGB channels only\n",
    "    if not args['pan_hierarchical']:\n",
    "        from PN_models.PN_Baseline import PredNet\n",
    "    else:\n",
    "        from PN_models.PN_Baseline import PredNet\n",
    "        print(\"Using Pan-Hierarchical Representation\")\n",
    "elif args[\"model_choice\"] == \"cl_delta\":\n",
    "    # Predict next frame and change from current frame\n",
    "    from PN_models.PN_CompLearning_Delta_Predictions import PredNet\n",
    "elif args[\"model_choice\"] == \"cl_recon\":\n",
    "    # Predict current and next frame\n",
    "    from PN_models.PN_CompLearning_Recon_Predictions import PredNet\n",
    "elif args[\"model_choice\"] == \"multi_channel\":\n",
    "    # Predict next frame along Disparity, Material Index, Object Index, \n",
    "    # Optical Flow, Motion Boundaries, and RGB channels all stacked together\n",
    "    assert args[\"dataset\"] == \"monkaa\" or args[\"dataset\"] == \"driving\", \"Multi-channel model only works with Monkaa or Driving dataset\"\n",
    "    from PN_models.PN_Multi_Channel import PredNet\n",
    "    bottom_layer_output_channels = 7 # 1 Disparity, 3 Optical Flow, 3 RGB\n",
    "    args[\"output_channels\"][0] = bottom_layer_output_channels\n",
    "else:\n",
    "    raise ValueError(\"Invalid model choice\")\n",
    "\n",
    "# where weights are loaded prior to eval\n",
    "if (args[\"dataset_weights\"], args[\"data_subset_weights\"]) in [\n",
    "    (\"rolling_square\", \"single_rolling_square\"),\n",
    "    (\"rolling_circle\", \"single_rolling_circle\"),\n",
    "]:\n",
    "    # where weights will be loaded/saved\n",
    "    weights_file = os.path.join(WEIGHTS_DIR, f\"para_prednet_\"+args[\"data_subset\"]+\"_weights.hdf5\")\n",
    "elif (args[\"dataset_weights\"], args[\"data_subset_weights\"]) in [\n",
    "    (\"all_rolling\", \"single\"),\n",
    "    (\"all_rolling\", \"multi\")\n",
    "]:\n",
    "    # where weights will be loaded/saved\n",
    "    weights_file = os.path.join(WEIGHTS_DIR, f\"para_prednet_\"+args[\"dataset_weights\"]+\"_\"+args[\"data_subset_weights\"]+\"_weights.hdf5\")\n",
    "elif args[\"dataset_weights\"] in [\"all_rolling\", \"ball_collisions\", \"SSM\"]:\n",
    "    # where weights will be loaded/saved\n",
    "    weights_file = os.path.join(WEIGHTS_DIR, f\"para_prednet_\"+args[\"dataset_weights\"]+\"_\"+args[\"data_subset_weights\"]+\"_weights.hdf5\")\n",
    "else:\n",
    "    # where weights will be loaded/saved\n",
    "    weights_file = os.path.join(WEIGHTS_DIR, f\"para_prednet_\"+args[\"dataset_weights\"]+\"_weights.hdf5\")\n",
    "# weights_file = os.path.join(f\"/home/evalexii/Documents/Thesis/code/parallel_prednet/model_weights/{args['dataset_weights']}/{args['data_subset_weights']}\", f\"para_prednet_{args['data_subset_weights']}_weights.hdf5\")\n",
    "assert os.path.exists(weights_file), \"Weights file not found\"\n",
    "if args['dataset'] != args['dataset_weights']: \n",
    "    print(f\"WARNING: dataset ({args['dataset']}) and dataset_weights ({args['dataset_weights']}/{args['data_subset_weights']}) do not match - generalizing...\") \n",
    "else:\n",
    "    print(f\"OK: dataset ({args['dataset']}) and dataset_weights ({args['dataset_weights']}/{args['dataset_weights']}) match\") \n",
    "\n",
    "# Training parameters\n",
    "nt = args[\"nt\"]  # number of time steps\n",
    "batch_size = args[\"batch_size\"]  # 4\n",
    "output_channels = args[\"output_channels\"]\n",
    "\n",
    "# Define image shape\n",
    "if args[\"dataset\"] == \"kitti\":\n",
    "    original_im_shape = (128, 160, 3)\n",
    "    im_shape = original_im_shape\n",
    "elif args[\"dataset\"] == \"monkaa\" or args[\"dataset\"] == \"driving\":\n",
    "    original_im_shape = (540, 960, 3)\n",
    "    downscale_factor = args[\"downscale_factor\"]\n",
    "    im_shape = (original_im_shape[0] // downscale_factor, original_im_shape[1] // downscale_factor, 3)\n",
    "elif args[\"dataset\"] in [\"rolling_square\", \"rolling_circle\"]:\n",
    "    original_im_shape = (50, 100, 3)\n",
    "    downscale_factor = args[\"downscale_factor\"]\n",
    "    im_shape = (original_im_shape[0] // downscale_factor, original_im_shape[1] // downscale_factor, 3) if args[\"resize_images\"] else original_im_shape\n",
    "else:\n",
    "    original_im_shape = (50, 50, 3)\n",
    "    downscale_factor = args[\"downscale_factor\"]\n",
    "    im_shape = (original_im_shape[0] // downscale_factor, original_im_shape[1] // downscale_factor, 3) if args[\"resize_images\"] else original_im_shape\n",
    "\n",
    "print(f\"Working on dataset: {args['dataset']}\")\n",
    "\n",
    "# Create PredNet\n",
    "if args[\"dataset\"] == \"kitti\":\n",
    "    # These are Kitti specific input shapes\n",
    "    inputs = (keras.Input(shape=(nt, im_shape[0], im_shape[1], 3)))\n",
    "    PN = PredNet(args, im_height=im_shape[0], im_width=im_shape[1])  # [3, 48, 96, 192]\n",
    "    outputs = PN(inputs)\n",
    "    PN = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "elif args[\"dataset\"] == \"monkaa\":\n",
    "    # These are Monkaa specific input shapes\n",
    "    inputs = (keras.Input(shape=(nt, im_shape[0], im_shape[1], 1)),\n",
    "        keras.Input(shape=(nt, im_shape[0], im_shape[1], 1)),\n",
    "        keras.Input(shape=(nt, im_shape[0], im_shape[1], 1)),\n",
    "        keras.Input(shape=(nt, im_shape[0], im_shape[1], 3)),\n",
    "        keras.Input(shape=(nt, im_shape[0], im_shape[1], 1)),\n",
    "        keras.Input(shape=(nt, im_shape[0], im_shape[1], 3)),\n",
    "    )\n",
    "    PN = PredNet(args, im_height=im_shape[0], im_width=im_shape[1])  # [3, 48, 96, 192]\n",
    "    outputs = PN(inputs)\n",
    "    PN = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "elif args[\"dataset\"] == \"driving\":\n",
    "    # These are driving specific input shapes\n",
    "    inputs = (keras.Input(shape=(nt, im_shape[0], im_shape[1], 1)),\n",
    "        keras.Input(shape=(nt, im_shape[0], im_shape[1], 3)),\n",
    "        keras.Input(shape=(nt, im_shape[0], im_shape[1], 3)),\n",
    "    )\n",
    "    PN = PredNet(args, im_height=im_shape[0], im_width=im_shape[1])  # [3, 48, 96, 192]\n",
    "    outputs = PN(inputs)\n",
    "    PN = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "else:\n",
    "    inputs = keras.Input(shape=(nt, im_shape[0], im_shape[1], 3))\n",
    "    PN_layer = PredNet(args, im_height=im_shape[0], im_width=im_shape[1])\n",
    "    PN_layer.output_mode = \"Intermediate_Activations\"#\"Prediction\"\n",
    "    PN_layer.continuous_eval = True\n",
    "    outputs = PN_layer(inputs)\n",
    "    PN = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "resos = PN.layers[-1].resolutions\n",
    "PN.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "print(\"PredNet compiled...\")\n",
    "PN.build(input_shape=(None, nt) + im_shape)\n",
    "print(PN.summary())\n",
    "num_layers = len(output_channels)  # number of layers in the architecture\n",
    "print(f\"{num_layers} PredNet layers with resolutions:\")\n",
    "for i in reversed(range(num_layers)):\n",
    "    print(f\"Layer {i+1}:  {resos[i][0]} x {resos[i][1]} x {output_channels[i]}\")\n",
    "\n",
    "# load previously saved weights\n",
    "try: \n",
    "    PN.load_weights(weights_file)\n",
    "    print(\"Weights loaded successfully...\")\n",
    "except: \n",
    "    raise ValueError(\"Weights don't fit - exiting...\")\n",
    "\n",
    "# Load dataset - only working for animations\n",
    "try:\n",
    "    test_data = hkl.load(DATA_DIR + f\"{args['data_subset']}_{args['data_subset_mode']}.hkl\")[0]\n",
    "except:\n",
    "    png_paths = [DATA_DIR + f\"{args['dataset']}/frames/{args['data_subset']}/\"]\n",
    "    # png_paths = [DATA_DIR + f\"{args['dataset']}/frames/{args['data_subset']}_{args['data_subset_mode']}/\"]\n",
    "    serialize_dataset(data_dirs, pfm_paths=[], pgm_paths=[], png_paths=png_paths, dataset_name=args['data_subset'], test_data=True)\n",
    "    print(\"Dataset serialized...\")\n",
    "    file = DATA_DIR + f\"{args['data_subset']}_{args['data_subset_mode']}.hkl\"\n",
    "    print(f\"Saved dataset to {file}\")\n",
    "    test_data = hkl.load(DATA_DIR + f\"{args['data_subset']}_{args['data_subset_mode']}.hkl\")[0]\n",
    "print(\"Test data ready...\")\n",
    "\n",
    "td_len = test_data.shape[0]\n",
    "PN = PN.layers[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    }
   ],
   "source": [
    "# DEBUG - check if the model is working\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/general_cross_static_2nd_stage_test.hkl\n",
      "state_max data for 'general_cross_static_2nd_stage_test' already exists...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m data_subset, data_subset_mode \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_subsets, data_subset_modes):\n\u001b[1;32m     19\u001b[0m     test_data_file \u001b[39m=\u001b[39m DATA_DIR \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdata_subset\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mdata_subset_mode\u001b[39m}\u001b[39;00m\u001b[39m.hkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 20\u001b[0m     test_data \u001b[39m=\u001b[39m hkl\u001b[39m.\u001b[39;49mload(test_data_file)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded \u001b[39m\u001b[39m{\u001b[39;00mtest_data_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(DATA_DIR \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mcollection_mode\u001b[39m}\u001b[39;00m\u001b[39m_data_\u001b[39m\u001b[39m{\u001b[39;00mdata_subset\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mdata_subset_mode\u001b[39m}\u001b[39;00m\u001b[39m.hkl\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/PN/lib/python3.11/site-packages/hickle/hickle.py:379\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file_obj, path, safe, filename)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[39mwith\u001b[39;00m LoaderManager\u001b[39m.\u001b[39mcreate_manager( h_root_group,\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m loader:\n\u001b[1;32m    378\u001b[0m         \u001b[39mwith\u001b[39;00m ReferenceManager\u001b[39m.\u001b[39mcreate_manager(h_root_group,pickle_loads) \u001b[39mas\u001b[39;00m memo:\n\u001b[0;32m--> 379\u001b[0m             _load(py_container, \u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m,h_root_group[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m],memo,loader) \u001b[39m#load_loader = load_loader)\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[39mreturn\u001b[39;00m py_container\u001b[39m.\u001b[39mconvert()\n\u001b[1;32m    382\u001b[0m \u001b[39m# Else, raise error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PN/lib/python3.11/site-packages/hickle/hickle.py:450\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(py_container, h_name, h_node, memo, loader)\u001b[0m\n\u001b[1;32m    447\u001b[0m py_subcontainer \u001b[39m=\u001b[39m py_container_class(h_node\u001b[39m.\u001b[39mattrs,base_type,py_obj_type)\n\u001b[1;32m    449\u001b[0m \u001b[39mfor\u001b[39;00m h_key,h_subnode \u001b[39min\u001b[39;00m py_subcontainer\u001b[39m.\u001b[39mfilter(h_node):\n\u001b[0;32m--> 450\u001b[0m     _load(py_subcontainer, h_key, h_subnode, memo ,loader)\n\u001b[1;32m    452\u001b[0m \u001b[39m# finalize sub item\u001b[39;00m\n\u001b[1;32m    453\u001b[0m sub_data \u001b[39m=\u001b[39m py_subcontainer\u001b[39m.\u001b[39mconvert()\n",
      "File \u001b[0;32m~/miniconda3/envs/PN/lib/python3.11/site-packages/hickle/hickle.py:461\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(py_container, h_name, h_node, memo, loader)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m \n\u001b[1;32m    457\u001b[0m     \u001b[39m# must be a dataset load it and append to parent container.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     \u001b[39m# In case no appropriate loader could be found use recover_custom_dataset\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[39m# instead to at least recover the contained data\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     load_fn \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mhkl_types_dict\u001b[39m.\u001b[39mget(base_type, recover_custom_dataset)\n\u001b[0;32m--> 461\u001b[0m     sub_data \u001b[39m=\u001b[39m load_fn(h_node,base_type,py_obj_type)\n\u001b[1;32m    462\u001b[0m     py_container\u001b[39m.\u001b[39mappend(h_name,sub_data,h_node\u001b[39m.\u001b[39mattrs)\n\u001b[1;32m    464\u001b[0m \u001b[39m# store loaded object for properly restoring additional references to it\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PN/lib/python3.11/site-packages/hickle/loaders/load_numpy.py:241\u001b[0m, in \u001b[0;36mload_ndarray_dataset\u001b[0;34m(h_node, base_type, py_obj_type)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[39mreturn\u001b[39;00m py_obj_type(data\u001b[39m=\u001b[39mh_node[()],dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    238\u001b[0m \u001b[39m# TODO how to restore other ndarray derived object_types\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m# simply using classname for casting does not work, in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# case they use the same interface like numpy.ndarray\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray(h_node[()], dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DATA COLLECTION CODE - AGGREGATION OR STATE DATA\n",
    "\n",
    "collection_mode = \"state_max\" # \"agg\", \"state\", or \"state_max\"\n",
    "\n",
    "data_subsets = [\n",
    "    \"general_cross_static_2nd_stage\",\n",
    "    \"general_ellipse_static_2nd_stage\",\n",
    "]\n",
    "\n",
    "data_subset_modes = [\n",
    "    \"test\",\n",
    "    \"test\"\n",
    "]\n",
    "\n",
    "state_orders = [\"R\", \"P\"]\n",
    "\n",
    "for data_subset, data_subset_mode in zip(data_subsets, data_subset_modes):\n",
    "\n",
    "    test_data_file = DATA_DIR + f\"{data_subset}_{data_subset_mode}.hkl\"\n",
    "    test_data = hkl.load(test_data_file)[0]\n",
    "    print(f\"Loaded {test_data_file}\")\n",
    "\n",
    "    if not os.path.exists(DATA_DIR + f\"/{collection_mode}_data_{data_subset}_{data_subset_mode}.hkl\"):\n",
    "        print(f\"Collecting {collection_mode} data...\")\n",
    "\n",
    "        # Assuming initialization and data loading is done here\n",
    "        start = 0\n",
    "        stop = td_len - 1\n",
    "        num_samples = td_len - 1\n",
    "        sample_shape = (1, 1, *test_data.shape[1:])\n",
    "\n",
    "        # Initialize lists to store intermediate data for each layer\n",
    "        # States_list = [[] for _ in PN.predlayers]\n",
    "        R_states_list = [[] for _ in PN.predlayers]\n",
    "        P_states_list = [[] for _ in PN.predlayers]\n",
    "\n",
    "        # initialize lists to hold global max pooled states\n",
    "        R_state_maxes = [[] for _ in PN.predlayers]\n",
    "        P_state_maxes = [[] for _ in PN.predlayers]\n",
    "\n",
    "        # initialize lists to hold top k% of channels by weight\n",
    "        R_agg_mtx = [np.zeros((PN.predlayers[j].output_channels)) for j in range(len(PN.predlayers))]\n",
    "        P_agg_mtx = [np.zeros((PN.predlayers[j].output_channels)) for j in range(len(PN.predlayers))]\n",
    "\n",
    "        # generic output\n",
    "        R_out = None\n",
    "        P_out = None\n",
    "        # states_out = None\n",
    "\n",
    "        # Prepare states\n",
    "        indices = np.random.permutation(range(start, stop))\n",
    "        for it, i in enumerate(indices[:num_samples]):\n",
    "            if it%100==0:print(f\"Sample {it+1}/{num_samples}...\")\n",
    "            PN.init_layer_states()\n",
    "            ground_truth_image = np.reshape(test_data[i], sample_shape)\n",
    "            predicted_image = PN(ground_truth_image)\n",
    "            predicted_image = PN(ground_truth_image)\n",
    "            # ground_truth_image = np.reshape(test_data[i+1], sample_shape)\n",
    "            # predicted_image = PN(ground_truth_image)\n",
    "            \n",
    "            # COLLECT ALL STATE DATA\n",
    "            if collection_mode == \"state\":\n",
    "                for j in range(len(PN.predlayers)):\n",
    "                    R_states_list[j].append(PN.predlayers[j].states[\"R\"][0])\n",
    "                    P_states_list[j].append(PN.predlayers[j].states[\"P\"][0])\n",
    "\n",
    "            # COLLECT GLOBAL MAX POOLED STATES\n",
    "            elif collection_mode == \"state_max\":\n",
    "                for j in range(len(PN.predlayers)):\n",
    "                    R_state_maxes[j].append(np.max(PN.predlayers[j].states[\"R\"][0], axis=(0,1)))\n",
    "                    P_state_maxes[j].append(np.max(PN.predlayers[j].states[\"P\"][0], axis=(0,1)))\n",
    "\n",
    "            # COLLECT AGGREGATION MATRICES\n",
    "            elif collection_mode == \"agg\":\n",
    "                # Aggregate top k% of channels by weight\n",
    "                # Need a vector of length equal to the number of channels in the layer\n",
    "                k = 0.1\n",
    "                for j in range(len(PN.predlayers)):\n",
    "                    R_max_pooled = np.max(PN.predlayers[j].states[\"R\"][0], axis=(0,1))\n",
    "                    P_max_pooled = np.max(PN.predlayers[j].states[\"P\"][0], axis=(0,1))\n",
    "                    R_norm = R_max_pooled / np.sum(R_max_pooled)\n",
    "                    P_norm = P_max_pooled / np.sum(P_max_pooled)\n",
    "                    R_sorted = np.argsort(R_norm)[::-1]\n",
    "                    P_sorted = np.argsort(P_norm)[::-1]\n",
    "                    R_sum = 0\n",
    "                    P_sum = 0\n",
    "                    R_indices = []\n",
    "                    P_indices = []\n",
    "                    for l in range(len(R_sorted)):\n",
    "                        if R_sum <= k:\n",
    "                            R_sum += R_norm[R_sorted[l]]\n",
    "                        if (R_sum <= k) or (l == 0):\n",
    "                            R_indices.append(R_sorted[l])\n",
    "                        else:\n",
    "                            break\n",
    "                    for l in range(len(R_sorted)):\n",
    "                        if P_sum <= k:\n",
    "                            P_sum += P_norm[P_sorted[l]]\n",
    "                        if (P_sum <= k) or (l == 0):\n",
    "                            P_indices.append(R_sorted[l])\n",
    "                        else:\n",
    "                            break\n",
    "                    R_agg_mtx[j][R_indices] += 1\n",
    "                    P_agg_mtx[j][P_indices] += 1\n",
    "\n",
    "        # COLLECT ALL STATE DATA \n",
    "        if collection_mode == \"state\":\n",
    "            R_out = R_states_list\n",
    "            P_out = P_states_list\n",
    "\n",
    "        # COLLECT GLOBAL MAX POOLED STATES\n",
    "        elif collection_mode == \"state_max\":\n",
    "            R_out = R_state_maxes\n",
    "            P_out = P_state_maxes\n",
    "\n",
    "        # COLLECT AGGREGATION MATRICES\n",
    "        elif collection_mode == \"agg\":\n",
    "            R_out = R_agg_mtx\n",
    "            P_out = P_agg_mtx\n",
    "\n",
    "        print(\"Done...\")\n",
    "        # Save intermediate state data\n",
    "        print(f\"Saving {collection_mode} data...\")\n",
    "        # if collection_mode == \"state\":\n",
    "        #     hkl.dump(states_out, DATA_DIR + f\"/{collection_mode}_data_{state_order}_{data_subset}_{data_subset_mode}.hkl\")\n",
    "        data_out = DATA_DIR + f\"/{collection_mode}_data_{data_subset}_{data_subset_mode}.hkl\"\n",
    "        hkl.dump([R_out, P_out], data_out)\n",
    "        print(f\"Saved {collection_mode} data to {data_out}\")\n",
    "        R_out, P_out = None, None\n",
    "        print(\"Done...\")\n",
    "\n",
    "    else:\n",
    "        print(f\"{collection_mode} data for '{data_subset}_{data_subset_mode}' already exists...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation matrix stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AGGREGATION MATRICES\n",
    "\n",
    "agg_datasets = [\n",
    "    DATA_DIR + f\"/agg_data_general_cross_static_2nd_stage_test.hkl\",\n",
    "    DATA_DIR + f\"/agg_data_general_ellipse_static_2nd_stage_test.hkl\",\n",
    "]\n",
    "\n",
    "''' Extract aggregation matrices after collecting '''\n",
    "R_agg_mtxs = [[] for _ in agg_datasets]\n",
    "P_agg_mtxs = [[] for _ in agg_datasets]\n",
    "\n",
    "for i in range(len(agg_datasets)):\n",
    "    R_agg_mtxs[i], P_agg_mtxs[i] = hkl.load(agg_datasets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT AGGREGATION MATRICES AND DIFFERENCE MATRICES\n",
    "\n",
    "# Plot the aggregate matrices\n",
    "fig, axs = plt.subplots(4, 2, figsize=(10, 15))\n",
    "fig.suptitle(\"Aggregate Winner Matrices\\n[Count indicates number of times out of 5000 a channel was in the top 10% of channels by weight]\")\n",
    "colors = ['blue','orange']\n",
    "for i in range(len(agg_datasets)):\n",
    "    for j in range(len(PN.predlayers)):\n",
    "        indices = range(len(R_agg_mtxs[i][j]))\n",
    "        axs[j,0].bar(indices,R_agg_mtxs[i][j], alpha=0.7, color=colors[i])\n",
    "        axs[j,1].bar(indices,P_agg_mtxs[i][j], alpha=0.7, color=colors[i])\n",
    "        axs[j,0].set_title(f\"R Aggregate Winners, Layer {j+1}\")\n",
    "        axs[j,1].set_title(f\"P Aggregate Winners, Layer {j+1}\")\n",
    "        axs[j,0].set_ylabel(\"Count\")\n",
    "        if j == 0:\n",
    "            axs[j,0].legend([\"Cross\", \"Ellipse\"])\n",
    "            axs[j,1].legend([\"Cross\", \"Ellipse\"])\n",
    "        elif j == 3:\n",
    "            axs[j,0].set_xlabel(\"Channel Index\")\n",
    "            axs[j,1].set_xlabel(\"Channel Index\")\n",
    "# plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"/home/evalexii/Documents/Thesis/code/parallel_prednet/results/agg_matrix_imgs/agg_matrix.png\")\n",
    "\n",
    "''' Calculate the difference matrices from the two datasets'''\n",
    "R_diffs = [[] for _ in range(len(agg_datasets))]\n",
    "P_diffs = [[] for _ in range(len(agg_datasets))]\n",
    "for i in range(len(agg_datasets)):\n",
    "    for j in range(len(PN.predlayers)):\n",
    "        R_diff = R_agg_mtxs[i][j] - R_agg_mtxs[1-i][j]\n",
    "        R_diff[R_diff < 0] = 0\n",
    "        P_diff = P_agg_mtxs[i][j] - P_agg_mtxs[1-i][j]\n",
    "        P_diff[P_diff < 0] = 0\n",
    "        R_diffs[i].append(R_diff)\n",
    "        P_diffs[i].append(P_diff)\n",
    "\n",
    "# Plot the difference matrices\n",
    "fig, axs = plt.subplots(4, 2, figsize=(10, 15))\n",
    "fig.suptitle(\"Aggregate Difference Matrices\\n[Count indicates number of times out of 5000 a channel was in the top 10% of channels by weight]\\n[Only positive differences between cross/ellipse datasets are shown]\")\n",
    "colors = ['blue','orange']\n",
    "for i in range(len(agg_datasets)):\n",
    "    for j in range(len(PN.predlayers)):\n",
    "        indices = range(len(R_diffs[i][j]))\n",
    "        axs[j,0].bar(indices,R_diffs[i][j], alpha=0.7, color=colors[i])\n",
    "        axs[j,1].bar(indices,P_diffs[i][j], alpha=0.7, color=colors[i])\n",
    "        axs[j,0].set_title(f\"R Aggregate Differences, Layer {j+1}\")\n",
    "        axs[j,1].set_title(f\"P Aggregate Differences, Layer {j+1}\")\n",
    "        axs[j,0].set_ylabel(\"Count\")\n",
    "        if j == 0:\n",
    "            axs[j,0].legend([\"Cross\", \"Ellipse\"])\n",
    "            axs[j,1].legend([\"Cross\", \"Ellipse\"])\n",
    "        if j == 3:\n",
    "            axs[j,0].set_xlabel(\"Channel Index\")\n",
    "            axs[j,1].set_xlabel(\"Channel Index\")\n",
    "# plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"/home/evalexii/Documents/Thesis/code/parallel_prednet/results/agg_matrix_imgs/agg_diff_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State max stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STATE MAXES\n",
    "\n",
    "state_datasets = [\n",
    "    DATA_DIR + f\"/state_max_data_general_cross_static_2nd_stage_test.hkl\",\n",
    "    DATA_DIR + f\"/state_max_data_general_ellipse_static_2nd_stage_test.hkl\",\n",
    "]\n",
    "\n",
    "# Post-process all states after collecting\n",
    "R_state_maxes = [[] for _ in state_datasets]\n",
    "P_state_maxes = [[] for _ in state_datasets]\n",
    "R_max_indices = [[] for _ in state_datasets]\n",
    "P_max_indices = [[] for _ in state_datasets]\n",
    "\n",
    "# if saved datasets are state maxes\n",
    "for i in range(len(state_datasets)):\n",
    "    R_state_maxes[i], P_state_maxes[i] = hkl.load(state_datasets[i])\n",
    "    for j in range(len(PN.predlayers)):\n",
    "        R_state_maxes[i][j] = np.array(R_state_maxes[i][j])\n",
    "        P_state_maxes[i][j] = np.array(P_state_maxes[i][j])\n",
    "\n",
    "# # if saved datasets are state tensors\n",
    "# for i in range(len(state_datasets)):\n",
    "#     R_states_list, P_states_list = hkl.load(state_datasets[i])\n",
    "#     for j in range(len(PN.predlayers)):\n",
    "#         R_states = np.array(R_states_list[j])\n",
    "#         P_states = np.array(P_states_list[j])\n",
    "        \n",
    "#         # Max pooling across all samples for each layer\n",
    "#         R_max_pooled = np.max(R_states, axis=(1, 2))  # Max pooling across spatial dimensions\n",
    "#         P_max_pooled = np.max(P_states, axis=(1, 2))\n",
    "        \n",
    "#         R_state_maxes[i].append(R_max_pooled)\n",
    "#         P_state_maxes[i].append(P_max_pooled)\n",
    "        \n",
    "#         # Find top-k indices\n",
    "#         num_filters = R_states.shape[-1]\n",
    "#         top_k = num_filters // 3\n",
    "        \n",
    "#         R_max_indices[i].append(np.argsort(R_max_pooled, axis=1)[:,-top_k:])\n",
    "#         P_max_indices[i].append(np.argsort(P_max_pooled, axis=1)[:,-top_k:])\n",
    "\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT ALL LAYER STATE MAXES\n",
    "\n",
    "# Calculate mean, std of max activations per layer, plot error bars\n",
    "# discard activations with std > 0.1\n",
    "# then plot top 10 activations with x-axis as filter index\n",
    "std_max = 0.1\n",
    "top_k = 10\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 15))\n",
    "labels = [\"Cross-Right\", \"Ellipse-Down\"]\n",
    "for k in range(len(state_datasets)):\n",
    "    for i in range(len(PN.predlayers)):\n",
    "        R_mean_o = np.mean(R_state_maxes[k][i], axis=0)\n",
    "        R_std_o = np.std(R_state_maxes[k][i], axis=0)\n",
    "        R_indices_o = np.arange(len(R_mean_o))\n",
    "        R_mean_i = R_mean_o[R_std_o < std_max]\n",
    "        R_mean = R_mean_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "        R_std_i = R_std_o[R_std_o < std_max]\n",
    "        R_std = R_std_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "        R_indices_i = R_indices_o[R_std_o < std_max]\n",
    "        R_indices = R_indices_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "        axs[0,i].errorbar(R_indices, R_mean, yerr=R_std, fmt='o', label=labels[k])\n",
    "        P_mean_o = np.mean(P_state_maxes[k][i], axis=0)\n",
    "        P_std_o = np.std(P_state_maxes[k][i], axis=0)\n",
    "        P_indices_o = np.arange(len(P_mean_o))\n",
    "        P_mean_i = P_mean_o[P_std_o < std_max]\n",
    "        P_mean = P_mean_i[np.argsort(P_mean_i)[-top_k:]]\n",
    "        P_std_i = P_std_o[P_std_o < std_max]\n",
    "        P_std = P_std_i[np.argsort(P_mean_i)[-top_k:]]\n",
    "        P_indices_i = P_indices_o[P_std_o < std_max]\n",
    "        P_indices = P_indices_i[np.argsort(P_mean_i)[-top_k:]]\n",
    "        axs[1,i].errorbar(P_indices, P_mean, yerr=P_std, fmt='o', label=labels[k])\n",
    "        # axs[0,i].set_ylim(-0.1, 1.1)\n",
    "        # axs[1,i].set_ylim(-0.1, 1.1)\n",
    "        axs[0,i].set_title(f\"R-State Layer {i+1}\")\n",
    "        axs[1,i].set_title(f\"P-State Layer {i+1}\")\n",
    "        axs[0,i].set_xlabel(\"Channel Index\")\n",
    "        axs[1,i].set_xlabel(\"Channel Index\")\n",
    "        axs[0,i].legend()\n",
    "        axs[1,i].legend()\n",
    "        \n",
    "fig.suptitle(f\"Top {top_k} R- / P-State Max Channel-Values with STD < {std_max}\")\n",
    "# axs[1].set_title(f\"Top {top_k} P State Max Values with STD < {std_max}\")\n",
    "plt.show()\n",
    "plt.savefig(\"/home/evalexii/Documents/Thesis/code/parallel_prednet/results/state_max_winner_imgs/state_max_winners.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT SINGLE LAYER STATE MAXES\n",
    "\n",
    "# Calculate mean, std of max activations per layer, plot error bars\n",
    "# discard activations with std > 0.1\n",
    "# then plot top 10 activations with x-axis as filter index\n",
    "std_max = 1\n",
    "top_k = 200\n",
    "fig, axs = plt.subplots(2, 1, figsize=(50, 50))\n",
    "labels = [\"Cross-Right\", \"Ellipse-Down\"]\n",
    "i = 3 # layer index (L-1)\n",
    "for k in range(len(state_datasets)):\n",
    "\n",
    "    R_mean_o = np.mean(R_state_maxes[k][i], axis=0)\n",
    "    R_std_o = np.std(R_state_maxes[k][i], axis=0)\n",
    "    R_indices_o = np.arange(len(R_mean_o))\n",
    "    R_mean_i = R_mean_o[R_std_o < std_max]\n",
    "    R_mean = R_mean_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "    R_std_i = R_std_o[R_std_o < std_max]\n",
    "    R_std = R_std_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "    R_indices_i = R_indices_o[R_std_o < std_max]\n",
    "    R_indices = R_indices_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "    P_mean_o = np.mean(P_state_maxes[k][i], axis=0)\n",
    "    P_std_o = np.std(P_state_maxes[k][i], axis=0)\n",
    "    P_indices_o = np.arange(len(P_mean_o))\n",
    "    P_mean_i = P_mean_o[P_std_o < std_max]\n",
    "    P_mean = P_mean_i[np.argsort(P_mean_i)[-top_k:]]\n",
    "    P_std_i = P_std_o[P_std_o < std_max]\n",
    "    P_std = P_std_i[np.argsort(P_mean_i)[-top_k:]]\n",
    "    P_indices_i = P_indices_o[P_std_o < std_max]\n",
    "    P_indices = P_indices_i[np.argsort(P_mean_i)[-top_k:]]\n",
    "    axs[0].errorbar(R_indices, R_mean, yerr=R_std, fmt='o', label=labels[k])\n",
    "    axs[1].errorbar(P_indices, P_mean, yerr=P_std, fmt='o', label=labels[k])\n",
    "    axs[0].set_ylim(-0.1, 1.1)\n",
    "    axs[1].set_ylim(-0.1, 1.1)\n",
    "    axs[0].set_title(f\"R-State Layer {i+1}\")\n",
    "    axs[1].set_title(f\"P-State Layer {i+1}\")\n",
    "    axs[0].set_xlabel(\"Channel Index\")\n",
    "    axs[1].set_xlabel(\"Channel Index\")\n",
    "    axs[0].legend()\n",
    "    axs[1].legend()\n",
    "fig.suptitle(f\"Top {top_k} R- / P-State Max Channel-Values with STD < {std_max}\")\n",
    "# axs[1].set_title(f\"Top {top_k} P State Max Values with STD < {std_max}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD STATE MAX EXTRACTION CODE\n",
    "\n",
    "# iterate through whole test dataset pulling out filters from each layer\n",
    "PN = PN.layers[-1]\n",
    "start = 0\n",
    "stop = td_len-1\n",
    "num_samples = td_len-1\n",
    "# initialize lists to hold global max pooled states\n",
    "R_state_maxes = [None]*len(PN.predlayers)\n",
    "P_state_maxes = [None]*len(PN.predlayers)\n",
    "R_max_indices = [None]*len(PN.predlayers)\n",
    "P_max_indices = [None]*len(PN.predlayers)\n",
    "all_R_states_maxes = None\n",
    "all_P_states_maxes = None\n",
    "all_R_max_indices = None\n",
    "all_P_max_indices = None\n",
    "for it, i in enumerate(random.sample(range(start, stop), num_samples)):\n",
    "    print(f\"Sample {it+1}/{num_samples}...\")\n",
    "    # if i > 0: break\n",
    "    # manually initialize PN layer states\n",
    "    PN.init_layer_states()\n",
    "    # run image through twice to get activation that captures class-recognition\n",
    "    # not necessary to feed second sequence image in, as the image only contributes to bottom-up error, but nonetheless...\n",
    "    ground_truth_image = np.reshape(test_data[i], (1, 1, *test_data.shape[1:]))\n",
    "    predicted_image = PN(ground_truth_image)\n",
    "    ground_truth_image = np.reshape(test_data[i+1], (1, 1, *test_data.shape[1:]))\n",
    "    predicted_image = PN(ground_truth_image)\n",
    "\n",
    "    # add all state tensors to lists\n",
    "    R_states = []\n",
    "    P_states = []\n",
    "    for j in range(len(PN.predlayers)):\n",
    "        R_states.append(PN.predlayers[j].states[\"R\"][0])\n",
    "        P_states.append(PN.predlayers[j].states[\"P\"][0])\n",
    "    \n",
    "    # perform global max pooling on each layer's R and P states\n",
    "    for j in range(len(PN.predlayers)):\n",
    "        R_state_maxes[j] = np.expand_dims(np.max(R_states[j], axis=(0,1)), axis=0) if R_state_maxes[j] is None else np.concatenate((R_state_maxes[j], np.expand_dims(np.max(R_states[j], axis=(0,1)), axis=0)), axis=0)\n",
    "        P_state_maxes[j] = np.expand_dims(np.max(P_states[j], axis=(0,1)), axis=0) if P_state_maxes[j] is None else np.concatenate((P_state_maxes[j], np.expand_dims(np.max(P_states[j], axis=(0,1)), axis=0)), axis=0)\n",
    "\n",
    "        num_filters = R_states[j].shape[-1]\n",
    "        assert R_states[j].shape[-1] == P_states[j].shape[-1]\n",
    "        top_k = int(num_filters/3)\n",
    "\n",
    "        R_max_indices[j] = np.expand_dims(np.argsort(R_state_maxes[j][-1])[-top_k:], axis=0) if R_max_indices[j] is None else np.concatenate((R_max_indices[j], np.expand_dims(np.argsort(R_state_maxes[j][-1])[:top_k], axis=0)), axis=0)\n",
    "        P_max_indices[j] = np.expand_dims(np.argsort(P_state_maxes[j][-1])[-top_k:], axis=0) if P_max_indices[j] is None else np.concatenate((P_max_indices[j], np.expand_dims(np.argsort(P_state_maxes[j][-1])[:top_k], axis=0)), axis=0)\n",
    "    \n",
    "    # also find pan-hierarchical distributed representations\n",
    "    all_R_states_maxes = np.expand_dims(np.concatenate([j[-1] for j in R_state_maxes], axis=0), axis=0) if all_R_states_maxes is None else np.concatenate((all_R_states_maxes, np.expand_dims(np.concatenate([j[-1] for j in R_state_maxes], axis=0), axis=0)), axis=0)\n",
    "    all_P_states_maxes = np.expand_dims(np.concatenate([j[-1] for j in P_state_maxes], axis=0), axis=0) if all_P_states_maxes is None else np.concatenate((all_P_states_maxes, np.expand_dims(np.concatenate([j[-1] for j in P_state_maxes], axis=0), axis=0)), axis=0)\n",
    "    all_R_max_indices = np.expand_dims(np.argsort(all_R_states_maxes[-1])[-10:], axis=0) if all_R_max_indices is None else np.concatenate((all_R_max_indices, np.expand_dims(np.argsort(all_R_states_maxes[-1])[:10], axis=0)), axis=0)\n",
    "    all_P_max_indices = np.expand_dims(np.argsort(all_P_states_maxes[-1])[-10:], axis=0) if all_P_max_indices is None else np.concatenate((all_P_max_indices, np.expand_dims(np.argsort(all_P_states_maxes[-1])[:10], axis=0)), axis=0)\n",
    "\n",
    "    # # plot filter weights for each layer\n",
    "    # num_layers = len(PN.predlayers)\n",
    "    # for layer in PN.predlayers:\n",
    "    #     for p_c_layer in layer.prediction.conv_layers:\n",
    "    #         for weights in p_c_layer.trainable_weights:\n",
    "    #             if len(weights.shape) == 1: continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EXAMNINATION\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def plot_model_architecture(base_model, model_name):\n",
    "    plot_model(base_model, show_shapes=True, to_file=model_name)\n",
    "    display(HTML('<img src=\"{}\" style=\"display:inline;margin:1px\"/>'.format(model_name)))\n",
    "\n",
    "plot_model_architecture(PN, 'PN_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient ascent to generate images that maximally activate PN Conv filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP FOR GRADIENT ASCENT ON FILTERS\n",
    "\n",
    "from keras import backend as K\n",
    "import time\n",
    "\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "\n",
    "def gradient_ascent(image_data, model, layer_name, filter_index, iterations=20):\n",
    "    # Assume image_data is a tf.Variable so gradients can be tracked\n",
    "    image_data = tf.Variable(image_data)\n",
    "    model.init_layer_states()\n",
    "\n",
    "    count = 0\n",
    "    bad_count = 0\n",
    "    continue_GA = True\n",
    "    prev_loss = 0\n",
    "    loss_tol = 0.005 # minimum percent change\n",
    "    # for i in range(iterations):\n",
    "    while continue_GA:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Need to watch the input image data\n",
    "            tape.watch(image_data)\n",
    "\n",
    "            # Get model outputs\n",
    "            intermediate_outputs = model(image_data) # run once if passing in a sequence\n",
    "            intermediate_outputs = model(image_data) # run twice to get intermediate activations based on image data\n",
    "\n",
    "            # Extract the activation of the specific filter from the intermediate outputs\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                activation = intermediate_outputs[layer_name][:, filter_index, :, :]\n",
    "            else:\n",
    "                activation = intermediate_outputs[layer_name][:, :, :, filter_index]\n",
    "\n",
    "            # Define the loss as the mean of the activations\n",
    "            loss = tf.reduce_mean(activation)\n",
    "\n",
    "            # You may add a regularization term to avoid saturation\n",
    "            # For example, maximize the diversity of activations across the channel\n",
    "            # clipped_activations = tf.clip_by_value(activation, 1e-8, 1.0)\n",
    "            # entropy_loss = -tf.reduce_sum(clipped_activations * tf.math.log(clipped_activations))\n",
    "            # # entropy_loss = -tf.reduce_sum(activation * tf.math.log(activation + 1e-10))\n",
    "            # loss = loss + 0.01 * entropy_loss\n",
    "\n",
    "            if count == 0:\n",
    "                prev_loss = loss\n",
    "                count += 1\n",
    "                if loss <= 0:\n",
    "                    continue_GA = False\n",
    "                    # print(f\"GA stopped for {layer_name} filter {filter_index} at iteration {count} with loss {loss}\")\n",
    "            else:\n",
    "                percent_change = abs((loss - prev_loss) / prev_loss)\n",
    "                if percent_change < loss_tol: bad_count += 1\n",
    "                else: bad_count = 0\n",
    "                \n",
    "                if (loss <= 0 or bad_count >= 3) or (count >= iterations):\n",
    "                    continue_GA = False\n",
    "                    # print(f\"GA stopped for {layer_name} filter {filter_index} at iteration {count} with loss {loss}\")\n",
    "                else:\n",
    "                    prev_loss = loss\n",
    "                    count += 1\n",
    "                    # print(f\"{layer_name} - Filter {filter_index} - Iteration {count} - Loss: {loss}\")\n",
    "\n",
    "            # if loss <= 0:\n",
    "            #     break\n",
    "\n",
    "        # Compute gradients with respect to the input image\n",
    "        grads = tape.gradient(loss, image_data)\n",
    "\n",
    "        # Normalize gradients\n",
    "        grads = normalize(grads)\n",
    "\n",
    "        # Apply gradients to the image data\n",
    "        image_data.assign_add(grads * 1.0)  # step size\n",
    "    \n",
    "    img = deprocess_image(image_data.numpy())\n",
    "    # kept_filters.append()\n",
    "    \n",
    "    return (filter_index, img, loss)\n",
    "\n",
    "base_model = PN\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 50\n",
    "img_height = 50\n",
    "input_img_data = np.random.random((1, args[\"nt\"], img_width, img_height, 3))\n",
    "input_img_data = ((input_img_data - 0.5) * 20 + 128) / 255.0\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict()\n",
    "for predlayer in base_model.layers:\n",
    "    Re = predlayer.representation\n",
    "    Pr = predlayer.prediction\n",
    "    layer_dict[Re.name] = [Re, predlayer]\n",
    "    layer_dict[Pr.name] = [Pr, predlayer]\n",
    "layers = [val for val in layer_dict.values()]\n",
    "\n",
    "# Identify the max-activated filters for each layer\n",
    "a = [np.argwhere(_r_agg_mtx) for _r_agg_mtx in R_agg_mtxs[0]] # matrices from first dataset\n",
    "b = [np.argwhere(_r_agg_mtx) for _r_agg_mtx in R_agg_mtxs[1]] # matrices from second dataset\n",
    "R_channels = [np.unique(np.concatenate((_a,_b), axis=0)) for _a, _b in zip(a,b)]\n",
    "a = [np.argwhere(_p_agg_mtx) for _p_agg_mtx in P_agg_mtxs[0]] # matrices from first dataset\n",
    "b = [np.argwhere(_p_agg_mtx) for _p_agg_mtx in P_agg_mtxs[1]] # matrices from second dataset\n",
    "P_channels = [np.unique(np.concatenate((_a,_b), axis=0)) for _a, _b in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM GRADIENT ASCENT ON ALL FILTERS\n",
    "\n",
    "filters_dict = dict()\n",
    "for sublayer, predlayer in layers:\n",
    "    layer_name = sublayer.name\n",
    "    layer_num = int(layer_name.split(\"_Layer\")[-1])\n",
    "    channels = R_channels[layer_num] if layer_name.split(\"_\")[0] == \"Representation\" else P_channels[layer_num]\n",
    "    layer = predlayer.get_layer(layer_name)\n",
    "    print(f'Processing {len(channels)} filters for layer: {layer_name}')\n",
    "    kept_filters = []\n",
    "    for filter_index in channels: # range(min(predlayer.output_channels, 100)):\n",
    "        # print('Processing filter %d' % filter_index)\n",
    "\n",
    "        start_time = time.time()\n",
    "        out = gradient_ascent(image_data=input_img_data, model=base_model, layer_name=layer_name, filter_index=filter_index, iterations=20)\n",
    "        kept_filters.append(out)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # print('--->Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "    filters_dict[layer_name] = kept_filters\n",
    "\n",
    "# for layer_name, kept_filters in filters_dict.items():\n",
    "#     print(layer_name, len(kept_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE IMGS FOR MAXIMALLY-ACTIVATED FILTERS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_kept_filters(kept_filters, layer_name, save_img=False):\n",
    "    kept_filters.sort(key=lambda x: x[2], reverse=True)\n",
    "    number_imgs = len(kept_filters)\n",
    "    # Determine the number of rows and columns based on the number of images\n",
    "    cols = min(number_imgs, 8)  # Up to 8 columns\n",
    "    rows = (number_imgs + 7) // 8  # Calculate rows needed, at most 8 images per row\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols * 2, rows * 3))\n",
    "    \n",
    "    # Flatten axes array for easier handling (in case of just one row, it might not be an array)\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "    \n",
    "    # Hide axes\n",
    "    for ax in axes:\n",
    "        ax.axis('off')  # Turn off the axis\n",
    "\n",
    "    # Simulate image data and plot images\n",
    "    for i in range(len(kept_filters)):\n",
    "        filter_index, img, loss = kept_filters[i]\n",
    "        # image_data = np.random.rand(10, 10)  # Random image data\n",
    "        img = np.squeeze(img, axis=(0,1))\n",
    "        axes[i].imshow(img, cmap='gray')  # Display the image\n",
    "        axes[i].set_title(f\"F{filter_index}-L:{loss:.2f}\")\n",
    "\n",
    "    # Set the margins between images\n",
    "    plt.subplots_adjust(wspace=0.15, hspace=0.25)  # Adjust the spacing\n",
    "\n",
    "    # Set the title\n",
    "    fig.suptitle(f\"Maximally Activated Filters for Layer: {layer_name}, sorted high-to-low by loss\", fontsize=16)\n",
    "\n",
    "    # Show the plot\n",
    "    # plt.show(block=True)\n",
    "\n",
    "    # Save the plot if specified\n",
    "    \n",
    "    if save_img:\n",
    "        folder = f\"./results/filter_imgs/\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        plt.savefig(folder + f\"{layer_name}_filters.png\")\n",
    "        plt.close()\n",
    "\n",
    "# Example usage:\n",
    "# create_image_grid(15)  # For instance, create a grid for 15 images\n",
    "\n",
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    plot_kept_filters(kept_filters, layer_name, save_img=True)\n",
    "    print(f\"Completed {layer_name}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction for conv filter inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R_agg_mtxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m layers \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m layer_dict\u001b[39m.\u001b[39mvalues()]\n\u001b[1;32m     11\u001b[0m \u001b[39m# Identify the max-activated filters for each layer\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m a \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39margwhere(_r_agg_mtx) \u001b[39mfor\u001b[39;00m _r_agg_mtx \u001b[39min\u001b[39;00m R_agg_mtxs[\u001b[39m0\u001b[39m]] \u001b[39m# matrices from first dataset\u001b[39;00m\n\u001b[1;32m     13\u001b[0m b \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39margwhere(_r_agg_mtx) \u001b[39mfor\u001b[39;00m _r_agg_mtx \u001b[39min\u001b[39;00m R_agg_mtxs[\u001b[39m1\u001b[39m]] \u001b[39m# matrices from second dataset\u001b[39;00m\n\u001b[1;32m     14\u001b[0m R_channels \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mconcatenate((_a,_b), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)) \u001b[39mfor\u001b[39;00m _a, _b \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(a,b)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'R_agg_mtxs' is not defined"
     ]
    }
   ],
   "source": [
    "# SETUP FOR DIMENSIONALITY REDUCTION FOR FILTERS\n",
    "\n",
    "layer_dict = dict()\n",
    "for predlayer in PN.layers:\n",
    "    Re = predlayer.representation\n",
    "    Pr = predlayer.prediction\n",
    "    layer_dict[Re.name] = [Re, predlayer]\n",
    "    layer_dict[Pr.name] = [Pr, predlayer]\n",
    "layers = [val for val in layer_dict.values()]\n",
    "\n",
    "# Identify the max-activated filters for each layer\n",
    "a = [np.argwhere(_r_agg_mtx) for _r_agg_mtx in R_agg_mtxs[0]] # matrices from first dataset\n",
    "b = [np.argwhere(_r_agg_mtx) for _r_agg_mtx in R_agg_mtxs[1]] # matrices from second dataset\n",
    "R_channels = [np.unique(np.concatenate((_a,_b), axis=0)) for _a, _b in zip(a,b)]\n",
    "a = [np.argwhere(_p_agg_mtx) for _p_agg_mtx in P_agg_mtxs[0]] # matrices from first dataset\n",
    "b = [np.argwhere(_p_agg_mtx) for _p_agg_mtx in P_agg_mtxs[1]] # matrices from second dataset\n",
    "P_channels = [np.unique(np.concatenate((_a,_b), axis=0)) for _a, _b in zip(a,b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM UMAP ON REPRESENTATION AND PREDICTION CONV FILTERS\n",
    "# Each output filter is a point in a high-dimensional space\n",
    "# These dimensions are the weights of the filter of number == (kernel height x kernel width x input channels)\n",
    "# We can reduce the dimensionality of these points to 2 or 3 dimensions using UMAP\n",
    "\n",
    "import numpy as np\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for sublayer, predlayer in layer_dict.values():\n",
    "    if sublayer.name.split(\"_\")[1] != \"Layer3\": continue\n",
    "\n",
    "    weights = sublayer.get_weights()\n",
    "    num_weights = np.prod(weights[0].shape[:-1])\n",
    "    for i, weight in enumerate(weights):\n",
    "        if len(weight.shape) == 1: continue\n",
    "        if weight.shape[-1] < 5: continue\n",
    "        # Example filter weights of shape (3, 3, 57, 3)\n",
    "        # Normally, these weights would be obtained from your trained model\n",
    "        filters = weight\n",
    "\n",
    "        # Reshape the filters\n",
    "        # We want a shape of (num_filters, spatial * channels) which translates to (3, 3*3*57)\n",
    "        flattened_filters = filters.reshape(-1, num_weights)\n",
    "\n",
    "        # Initialize UMAP. You can adjust the parameters like n_neighbors and min_dist based on your specific dataset\n",
    "        reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='euclidean')\n",
    "\n",
    "        # Fit and transform the data\n",
    "        embedding = reducer.fit_transform(flattened_filters)\n",
    "\n",
    "        # Plot the transformed filters\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(embedding[:, 0], embedding[:, 1], marker='o')\n",
    "        plt.title(f'UMAP of Convolutional Filters for {sublayer.weights[i].name}')\n",
    "        plt.xlabel('UMAP Component 1')\n",
    "        plt.ylabel('UMAP Component 2')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM UMAP or PCA ON REPRESENTATION AND PREDICTION CONV FILTERS\n",
    "# Each output filter is a point in a high-dimensional space\n",
    "# These dimensions are the weights of the filter of number == (kernel height x kernel width x input channels)\n",
    "# We can reduce the dimensionality of these points to 2 or 3 dimensions using PCA\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "\n",
    "method = \"UMAP\" # \"PCA\" or \"UMAP\n",
    "\n",
    "# rows are for layers\n",
    "# columns are for representation (x4) / prediction (x1)\n",
    "fig, axs = plt.subplots(4, 5, figsize=(15, 15))\n",
    "fig.suptitle(f\"{method} of Convolutional Filters for Representation and Prediction Layers - Red are Agg Winners\")\n",
    "\n",
    "for i, layer_details in enumerate(layer_dict.values()):\n",
    "    sublayer, predlayer = layer_details\n",
    "    # if sublayer.name.split(\"_\")[1] != \"Layer0\": continue\n",
    "    layer_num = int(sublayer.name.split(\"Layer\")[1])\n",
    "    layer_type = sublayer.name.split(\"_\")[0]\n",
    "\n",
    "    weights = sublayer.get_weights()\n",
    "    weights = [w for w in weights if len(w.shape) > 1]\n",
    "    num_weights = np.prod(weights[0].shape[:-1])\n",
    "    for j, weight in enumerate(weights):\n",
    "\n",
    "        # if len(weight.shape) == 1: continue\n",
    "        # Example filter weights of shape (3, 3, 57, 3)\n",
    "        # Normally, these weights would be obtained from your trained model\n",
    "        filters = weight\n",
    "\n",
    "        # Reshape the filters\n",
    "        # We want a shape of (num_filters, spatial * channels) which translates to (3, 3*3*57)\n",
    "        flattened_filters = filters.reshape(-1, num_weights)\n",
    "\n",
    "        if method == \"PCA\":\n",
    "            # Perform PCA to reduce dimensions, let's say to 2 components for easy visualization\n",
    "            reducer = PCA(n_components=2)\n",
    "        elif method == \"UMAP\":\n",
    "            if flattened_filters.shape[0] == 3:\n",
    "                continue\n",
    "            # Initialize UMAP. You can adjust the parameters like n_neighbors and min_dist based on your specific dataset\n",
    "            reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='euclidean')\n",
    "\n",
    "        # Fit and transform the data\n",
    "        transformed_filters = reducer.fit_transform(flattened_filters)\n",
    "\n",
    "        # Plot the transformed filters\n",
    "        if layer_type == \"Representation\":\n",
    "            weight_letter = sublayer.weights[2*j].name.split(\"Conv_\")[-1][0]\n",
    "            colors = ['blue'] * transformed_filters.shape[0]\n",
    "            if weight_letter == 'o': \n",
    "                for id in R_channels[layer_num]:\n",
    "                    colors[id] = 'red'\n",
    "            axs[layer_num,j].scatter(transformed_filters[:, 0], transformed_filters[:, 1], marker='o', color=colors)\n",
    "            axs[layer_num,j].set_title(f'R-{layer_num}-Conv_{weight_letter}')\n",
    "        else:\n",
    "            colors = ['blue'] * transformed_filters.shape[0]\n",
    "            for id in R_channels[layer_num]:\n",
    "                    colors[id] = 'red'\n",
    "            axs[layer_num,4].scatter(transformed_filters[:, 0], transformed_filters[:, 1], marker='o', color=colors)\n",
    "            axs[layer_num,4].set_title(f'P-{layer_num}')\n",
    "        # plt.scatter(transformed_filters[:, 0], transformed_filters[:, 1], marker='o')\n",
    "        # plt.title(f'PCA of Convolutional Filters for {sublayer.weights[j].name}')\n",
    "folder = f\"./results/dim_reduc_filters/\"\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "[axs[-1,i].set_xlabel(f'{method} Component 1') for i in range(5)]\n",
    "[axs[i,0].set_ylabel(f'{method} Component 2') for i in range(4)]\n",
    "plt.savefig(folder + f\"{method}_filters.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction for conv feature map inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD STATE DATA\n",
    "\n",
    "state_datasets = [\n",
    "    DATA_DIR + f\"/state_data_general_cross_static_2nd_stage_test.hkl\",\n",
    "    DATA_DIR + f\"/state_data_general_ellipse_static_2nd_stage_test.hkl\",\n",
    "]\n",
    "\n",
    "# Post-process all states after collecting\n",
    "R_states = [[] for _ in state_datasets]\n",
    "P_states = [[] for _ in state_datasets]\n",
    "\n",
    "# if saved datasets are state maxes\n",
    "for i in range(len(state_datasets)):\n",
    "    R_states[i], P_states[i] = hkl.load(state_datasets[i])\n",
    "    for j in range(len(PN.predlayers)):\n",
    "        R_states[i][j] = np.array(R_states[i][j])\n",
    "        P_states[i][j] = np.array(P_states[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROCESS STATE DATA FOR DIMENSIONALITY REDUCTION\n",
    "\n",
    "num_samples = len(R_states[0][0])\n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "\n",
    "# Create combined-dataset state tensors via concatenation\n",
    "R_states_combined = [np.concatenate((R_states[0][j], R_states[1][j]), axis=0) for j in range(len(PN.predlayers))]\n",
    "P_states_combined = [np.concatenate((P_states[0][j], P_states[1][j]), axis=0) for j in range(len(PN.predlayers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM PCA ON STATE DATA\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "combined_state_sets = [R_states_combined, P_states_combined]\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 15))\n",
    "fig.suptitle(f'PCA of R/P-State Feature Maps')\n",
    "\n",
    "for i in range(len(PN.predlayers)):\n",
    "    # if i > 0: break\n",
    "\n",
    "    combined_feature_maps_set = [combined_state_sets[0][i], combined_state_sets[1][i]] # shape (num_samples, spatial, spatial, channels)\n",
    "    num_features = np.prod(combined_feature_maps_set[0].shape[1:])\n",
    "    assert combined_feature_maps_set[0].shape[1:] == combined_feature_maps_set[1].shape[1:], \"Feature maps should have the same length\"\n",
    "\n",
    "    # Reshape the filters\n",
    "    # We want a shape of (num_samples, spatial * spatial * channels)\n",
    "    combined_flattened_feature_maps_set = [feature_maps.reshape(-1, num_features) for feature_maps in combined_feature_maps_set]\n",
    "\n",
    "    # Fit PCA to combined datasets (one PCA for each R&P)\n",
    "    pca_set = [PCA(n_components=2) for _ in range(len(combined_state_sets))]\n",
    "    pca_set = [pca.fit(flattened_feature_maps) for pca, flattened_feature_maps in zip(pca_set, combined_flattened_feature_maps_set)]\n",
    "    \n",
    "    # Flatten the feature maps for each dataset separately and then transform them using the trained PCAs\n",
    "    flattened_feature_maps_set_cross = [combined_flattened_feature_maps[:num_samples] for combined_flattened_feature_maps in combined_flattened_feature_maps_set]\n",
    "    flattened_feature_maps_set_ellipse = [combined_flattened_feature_maps[num_samples:] for combined_flattened_feature_maps in combined_flattened_feature_maps_set]\n",
    "\n",
    "    # Apply the trained PCA to the flattened feature maps\n",
    "    transformed_feature_maps_set_cross = [pca.transform(flattened_feature_maps) for pca, flattened_feature_maps in zip(pca_set, flattened_feature_maps_set_cross)]\n",
    "    transformed_feature_maps_set_ellipse = [pca.transform(flattened_feature_maps) for pca, flattened_feature_maps in zip(pca_set, flattened_feature_maps_set_ellipse)]\n",
    "\n",
    "    # Plot the transformed filters\n",
    "    [axs[j,i].scatter(transformed_feature_maps[:, 0], transformed_feature_maps[:, 1], color='red', marker='o', label='cross') for j, transformed_feature_maps in enumerate(transformed_feature_maps_set_cross)]\n",
    "    [axs[j,i].scatter(transformed_feature_maps[:, 0], transformed_feature_maps[:, 1], color='blue', marker='+', alpha=1, label='ellipse') for j, transformed_feature_maps in enumerate(transformed_feature_maps_set_ellipse)]\n",
    "    axs[0,i].set_title(f'R-State Layer {i}')\n",
    "    axs[1,i].set_title(f'P-State Layer {i}')\n",
    "    axs[0,i].set_xlabel('Principal Component 1')\n",
    "    axs[1,i].set_xlabel('Principal Component 1')\n",
    "    axs[0,i].set_ylabel('Principal Component 2')\n",
    "    axs[1,i].set_ylabel('Principal Component 2')\n",
    "    axs[0,i].legend()\n",
    "    axs[1,i].legend()\n",
    "    # plt.title(f'PCA of {name} feature maps for Layer {i}')\n",
    "    # plt.xlabel('Principal Component 1')\n",
    "    # plt.ylabel('Principal Component 2')\n",
    "    # plt.grid(True)\n",
    "folder = f\"./results/dim_reduc_feature_maps/\"\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "plt.savefig(folder + f\"PCA_feature_maps.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM UMAP ON STATE DATA\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "combined_state_sets = [R_states_combined, P_states_combined]\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(20, 15))\n",
    "fig.suptitle(f'UMAP of R/P-State Feature Maps')\n",
    "\n",
    "for i in range(len(PN.predlayers)):\n",
    "    # if i > 0: break\n",
    "\n",
    "    combined_feature_maps_set = [combined_state_sets[0][i], combined_state_sets[1][i]] # shape (num_samples, spatial, spatial, channels)\n",
    "    num_features = np.prod(combined_feature_maps_set[0].shape[1:])\n",
    "    assert combined_feature_maps_set[0].shape[1:] == combined_feature_maps_set[1].shape[1:], \"Feature maps should have the same length\"\n",
    "\n",
    "    # Reshape the filters\n",
    "    # We want a shape of (num_samples, spatial * spatial * channels)\n",
    "    combined_flattened_feature_maps_set = [feature_maps.reshape(-1, num_features) for feature_maps in combined_feature_maps_set]\n",
    "\n",
    "    # Fit UMAP to combined datasets (one UMAP for each R&P)\n",
    "    # Initialize UMAP. You can adjust the parameters like n_neighbors and min_dist based on your specific dataset\n",
    "    umap_set = [umap.UMAP(n_neighbors=5, min_dist=0.3, metric='euclidean') for _ in range(len(combined_state_sets))]\n",
    "    umap_set = [umap.fit(combined_flattened_feature_maps) for umap, combined_flattened_feature_maps in zip(umap_set, combined_flattened_feature_maps_set)]\n",
    "\n",
    "    # Flatten the feature maps for each dataset separately and then transform them using the trained PCAs\n",
    "    flattened_feature_maps_set_cross = [combined_flattened_feature_maps[:num_samples] for combined_flattened_feature_maps in combined_flattened_feature_maps_set]\n",
    "    flattened_feature_maps_set_ellipse = [combined_flattened_feature_maps[num_samples:] for combined_flattened_feature_maps in combined_flattened_feature_maps_set]\n",
    "\n",
    "    # Apply UMAP to the flattened feature maps\n",
    "    transformed_feature_maps_set_cross = [umap.transform(flattened_feature_maps) for umap, flattened_feature_maps in zip(umap_set, flattened_feature_maps_set_cross)]\n",
    "    transformed_feature_maps_set_ellipse = [umap.transform(flattened_feature_maps) for umap, flattened_feature_maps in zip(umap_set, flattened_feature_maps_set_ellipse)]\n",
    "\n",
    "    # Plot the transformed filters\n",
    "    [axs[j,i].scatter(transformed_feature_maps[:, 0], transformed_feature_maps[:, 1], color='red', marker='o', label='cross') for j, transformed_feature_maps in enumerate(transformed_feature_maps_set_cross)]\n",
    "    [axs[j,i].scatter(transformed_feature_maps[:, 0], transformed_feature_maps[:, 1], color='blue', marker='+', alpha=1, label='ellipse') for j, transformed_feature_maps in enumerate(transformed_feature_maps_set_ellipse)]\n",
    "    axs[0,i].set_title(f'R-State Layer {i}')\n",
    "    axs[1,i].set_title(f'P-State Layer {i}')\n",
    "    axs[0,i].set_xlabel('Umap Component 1')\n",
    "    axs[1,i].set_xlabel('Umap Component 1')\n",
    "    axs[0,i].set_ylabel('Umap Component 2')\n",
    "    axs[1,i].set_ylabel('Umap Component 2')\n",
    "    axs[0,i].legend()\n",
    "    axs[1,i].legend()\n",
    "    # plt.title(f'PCA of {name} feature maps for Layer {i}')\n",
    "    # plt.xlabel('Principal Component 1')\n",
    "    # plt.ylabel('Principal Component 2')\n",
    "    # plt.grid(True)\n",
    "folder = f\"./results/dim_reduc_feature_maps/\"\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "plt.savefig(folder + f\"UMAP_feature_maps.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct conv filter and feature map inspection (lower layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions from Top-Down Influence only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test image\n",
    "test_data_id = np.random.randint(0, test_data.shape[0]-1)\n",
    "ground_truth_image = test_data[test_data_id]\n",
    "print(ground_truth_image.shape)\n",
    "plt.imshow(ground_truth_image)\n",
    "plt.title(f\"Test Image {test_data_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation_Layer0 (1, 50, 50, 3)\n",
      "Prediction_Layer0 (1, 50, 50, 3)\n",
      "fasd\n",
      "Representation_Layer1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (1, 25, 25, 48)\n",
      "Prediction_Layer1 (1, 25, 25, 48)\n",
      "Representation_Layer2 (1, 12, 12, 96)\n",
      "Prediction_Layer2 (1, 12, 12, 96)\n",
      "Representation_Layer3 (1, 6, 6, 192)\n",
      "Prediction_Layer3 (1, 6, 6, 192)\n",
      "Representation_Layer0 (1, 50, 50, 3)\n",
      "Prediction_Layer0 (1, 50, 50, 3)\n",
      "fasd\n",
      "Representation_Layer1 (1, 25, 25, 48)\n",
      "Prediction_Layer1 (1, 25, 25, 48)\n",
      "Representation_Layer2 (1, 12, 12, 96)\n",
      "Prediction_Layer2 (1, 12, 12, 96)\n",
      "Representation_Layer3 (1, 6, 6, 192)\n",
      "Prediction_Layer3 (1, 6, 6, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation_Layer0 (1, 50, 50, 3)\n",
      "Prediction_Layer0 (1, 50, 50, 3)\n",
      "fasd\n",
      "Representation_Layer1 (1, 25, 25, 48)\n",
      "Prediction_Layer1 (1, 25, 25, 48)\n",
      "Representation_Layer2 (1, 12, 12, 96)\n",
      "Prediction_Layer2 (1, 12, 12, 96)\n",
      "Representation_Layer3 (1, 6, 6, 192)\n",
      "Prediction_Layer3 (1, 6, 6, 192)\n",
      "Representation_Layer0 (1, 50, 50, 3)\n",
      "Prediction_Layer0 (1, 50, 50, 3)\n",
      "fasd\n",
      "Representation_Layer1 (1, 25, 25, 48)\n",
      "Prediction_Layer1 (1, 25, 25, 48)\n",
      "Representation_Layer2 (1, 12, 12, 96)\n",
      "Prediction_Layer2 (1, 12, 12, 96)\n",
      "Representation_Layer3 (1, 6, 6, 192)\n",
      "Prediction_Layer3 (1, 6, 6, 192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation_Layer0 (1, 50, 50, 3)\n",
      "Prediction_Layer0 (1, 50, 50, 3)\n",
      "fasd\n",
      "Representation_Layer1 (1, 25, 25, 48)\n",
      "Prediction_Layer1 (1, 25, 25, 48)\n",
      "Representation_Layer2 (1, 12, 12, 96)\n",
      "Prediction_Layer2 (1, 12, 12, 96)\n",
      "Representation_Layer3 (1, 6, 6, 192)\n",
      "Prediction_Layer3 (1, 6, 6, 192)\n"
     ]
    }
   ],
   "source": [
    "# ACTIVATE AND PREDICT ON TEST DATA\n",
    "\n",
    "# # load state maxes\n",
    "\n",
    "# state_datasets = [\n",
    "#     DATA_DIR + f\"/state_max_data_general_cross_static_2nd_stage_test.hkl\",\n",
    "#     DATA_DIR + f\"/state_max_data_general_ellipse_static_2nd_stage_test.hkl\",\n",
    "# ]\n",
    "\n",
    "# # Post-process all states after collecting\n",
    "# R_state_maxes = [[] for _ in state_datasets]\n",
    "# P_state_maxes = [[] for _ in state_datasets]\n",
    "# R_max_indices = [[] for _ in state_datasets]\n",
    "# P_max_indices = [[] for _ in state_datasets]\n",
    "\n",
    "# # if saved datasets are state maxes\n",
    "# for i in range(len(state_datasets)):\n",
    "#     R_state_maxes[i], P_state_maxes[i] = hkl.load(state_datasets[i])\n",
    "#     for j in range(len(PN.predlayers)):\n",
    "#         R_state_maxes[i][j] = np.array(R_state_maxes[i][j])\n",
    "#         P_state_maxes[i][j] = np.array(P_state_maxes[i][j])\n",
    "\n",
    "# Assuming initialization and data loading is done here\n",
    "start = 0\n",
    "stop = td_len - 1\n",
    "num_samples = 1#td_len - 1\n",
    "sample_shape = (1, 1, *test_data.shape[1:])\n",
    "mode = \"top_layers_influence\" # \"top_layers_influence\" or \"single_influence\" or \"state_max_winners\"\n",
    "filtering = \"_layer4_winners\" # \"_layer4_winners\" or \"\"\n",
    "\n",
    "'''\n",
    "For _layer4_winners, paste the following into PN_Baseline.py under top-layer top-down pass\n",
    "\n",
    "                        losing_ids = [  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
    "                                            14,  15,  16,  17,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
    "                                            28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
    "                                            41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,\n",
    "                                            54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
    "                                            67,  68,  69,  70,  71,  72,  73,  74,  75,  77,  79,  80,  81,\n",
    "                                            82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  93,  94,  95,\n",
    "                                            97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
    "                                            110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 122, 123,\n",
    "                                            124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136,\n",
    "                                            137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,\n",
    "                                            150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
    "                                            164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177,\n",
    "                                            179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]\n",
    "                        R = self.predlayers[l].states[\"R\"]\n",
    "                        # set losing ids to 0 - Create a mask for the channels\n",
    "                        mask = tf.constant([i not in losing_ids for i in range(R.shape[-1])], dtype=tf.float32)\n",
    "                        # Reshape mask to be broadcastable across the batch and spatial dimensions\n",
    "                        mask = tf.reshape(mask, [1, 1, 1, R.shape[-1]])\n",
    "                        # Apply mask to the representation\n",
    "                        self.predlayers[l].states[\"R\"] = R * mask\n",
    "'''\n",
    "\n",
    "if mode == \"state_max_winners\":\n",
    "    # Calculate mean, std of max activations per layer, plot error bars\n",
    "    # discard activations with std > 0.1\n",
    "    # then plot top 10 activations with x-axis as filter index\n",
    "    std_max = 0.1\n",
    "    top_k = 10\n",
    "    labels = {\"Cross-Right\":0, \"Ellipse-Down\":1}\n",
    "    layer = 3\n",
    "    dataset = \"Ellipse-Down\"\n",
    "    dataset_num = labels[dataset]\n",
    "    R_winning_indices_set = [[] for _ in state_datasets]\n",
    "\n",
    "    for ds_num in range(len(state_datasets)):\n",
    "        R_mean_o = np.mean(R_state_maxes[ds_num][layer], axis=0)\n",
    "        R_std_o = np.std(R_state_maxes[ds_num][layer], axis=0)\n",
    "        R_indices_o = np.arange(len(R_mean_o))\n",
    "        R_mean_i = R_mean_o[R_std_o < std_max]\n",
    "        # R_mean = R_mean_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "        # R_std_i = R_std_o[R_std_o < std_max]\n",
    "        # R_std = R_std_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "        R_indices_i = R_indices_o[R_std_o < std_max]\n",
    "        R_winning_indices = R_indices_i[np.argsort(R_mean_i)[-top_k:]]\n",
    "        R_winning_indices_set[ds_num] = R_winning_indices\n",
    "\n",
    "    # Now, I have the indices of the top-k filters for each layer that \n",
    "    # have the highest mean activation and low-enough standard deviation. \n",
    "\n",
    "    # I want to zero out the top-layer representation and prediction \n",
    "    # feature maps for all channels except the top-k ones. Then, I want to \n",
    "    # plot the activations of these top-k filters for each layer in response to the test image.\n",
    "\n",
    "    # Prepare test image\n",
    "    unique_cross_winners = []\n",
    "    unique_cross_losers = []\n",
    "    unique_ellipse_winners = []\n",
    "    unique_ellipse_losers = []\n",
    "\n",
    "    cross_winners = R_winning_indices_set[0]\n",
    "    ellipse_winners = R_winning_indices_set[1]\n",
    "    unique_cross_winners = np.setdiff1d(cross_winners, ellipse_winners)\n",
    "    unique_ellipse_winners = np.setdiff1d(ellipse_winners, cross_winners)\n",
    "    cross_losers = np.setdiff1d(np.arange(R_state_maxes[0][layer].shape[-1]), cross_winners)\n",
    "    ellipse_losers = np.setdiff1d(np.arange(R_state_maxes[1][layer].shape[-1]), ellipse_winners)\n",
    "\n",
    "test_data_id = 489 # np.random.randint(0, test_data.shape[0]-1) # 489\n",
    "ground_truth_image = np.reshape(test_data[test_data_id], sample_shape)\n",
    "\n",
    "fig, axs = plt.subplots(2*5, 5, figsize=(5, 10))\n",
    "fig.suptitle(f'Representations and Predictions\\nInfluenced by Top Layers\\nLayer 4 Filtered for Winning Channels')\n",
    "axs[0,0].imshow(ground_truth_image[0,0])\n",
    "\n",
    "# Prepare states\n",
    "for i in range(5):\n",
    "    PN.init_layer_states()\n",
    "    intermediate_activations = PN(ground_truth_image) # error now populated at all levels based on bottom-up pass, reps still random\n",
    "    if i >= 1:\n",
    "        # We now want to clear the error states at all layers but the top one and then call again\n",
    "        for j in range(len(PN.predlayers)):\n",
    "            if mode == \"top_layers_influence\": \n",
    "                if j > i-1: continue # progressively clears states from lower layers\n",
    "            elif mode == \"single_influence\": \n",
    "                if j == i-1: continue # clears states from all layers but one\n",
    "            PN.predlayers[j].states[\"R\"] = np.zeros(PN.predlayers[j].states[\"R\"].shape)\n",
    "            PN.predlayers[j].states[\"P\"] = np.zeros(PN.predlayers[j].states[\"P\"].shape) \n",
    "            PN.predlayers[j].states[\"E\"] = np.zeros(PN.predlayers[j].states[\"E\"].shape)            \n",
    "    intermediate_activations = PN(ground_truth_image)\n",
    "\n",
    "    for name, state in intermediate_activations.items():\n",
    "        print(name, state.shape)\n",
    "        state = state[0] # remove batch dimension\n",
    "        layer_num = int(name.split(\"Layer\")[-1])\n",
    "        # depth-wise average or max-pooling\n",
    "        if layer_num > 0:\n",
    "            # mean\n",
    "            state = np.mean(state, axis=-1)\n",
    "            \n",
    "            # or, max\n",
    "            # channel_maxes = np.max(state, axis=(0,1))\n",
    "            # max_channel = np.argmax(channel_maxes)\n",
    "            # state = state[:,:,max_channel]\n",
    "        row = 0 + i*2 if name.split(\"_\")[0] == \"Representation\" else 1 + i*2\n",
    "        col = int(name.split(\"Layer\")[-1]) + 1\n",
    "        if name.split(\"_\")[0] == \"Prediction\" and layer_num == 0:\n",
    "            axs[row,col].imshow(state, cmap='hot')\n",
    "        else: \n",
    "            axs[row,col].imshow(state, cmap='hot')\n",
    "        axs[row,col].axis('off')\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        axs[i,0].axis('off')\n",
    "\n",
    "plt.show()\n",
    "path = \"/home/evalexii/Documents/Thesis/code/parallel_prednet/results/top_down_influence_imgs/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "plt.savefig(path + f\"{mode}{filtering}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot samples from each test video set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIFY PATHS AND CREATE PLOTS\n",
    "\n",
    "from data_utils import plot_video_sequences\n",
    "\n",
    "data_paths = [\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/general_shape_strafing/frames/general_cross_R_test\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/general_shape_strafing/frames/general_ellipse_D_test\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/multi_gen_shape_strafing/frames/multi_gen_shape_test\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/class_cond_shape_strafing/frames/class_cond_shape_2nd_stage\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/world_cond_shape_strafing/frames/world_cond_shape_2nd_stage\",\n",
    "]\n",
    "\n",
    "save_paths = [\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/general_shape_strafing/test_sample.png\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/general_shape_strafing/test_sample.png\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/multi_gen_shape_strafing/test_sample.png\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/class_cond_shape_strafing/test_sample.png\",\n",
    "    \"/home/evalexii/Documents/Thesis/code/parallel_prednet/data/animations/world_cond_shape_strafing/test_sample.png\",\n",
    "]\n",
    "\n",
    "for dp, sp in zip(data_paths, save_paths):\n",
    "    plot_video_sequences(data_path=dp, save_path=sp)\n",
    "    # input(\"Press Enter to continue...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
