{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previously serialized dataset.\n",
      "Begin tf.data.Dataset creation at 7.703399751335382e-05 seconds.\n",
      "3 datasets created.\n",
      "End tf.data.Dataset creation at 6.435531076996995 seconds.\n",
      "Train size: 106\n",
      "Validation size: 22\n",
      "Test size: 22\n",
      "All datasets created successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# or '2' to filter out INFO messages too\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from config import update_settings, get_settings\n",
    "\n",
    "update_settings('laptop', 'monkaa')\n",
    "DATA_DIR, WEIGHTS_DIR, RESULTS_SAVE_DIR, LOG_DIR = get_settings()['dirs']\n",
    "from data_utils import create_dataset_from_serialized_generator\n",
    "\n",
    "# dataset = tf.data.Dataset.range(10)\n",
    "# tempdataset = dataset.take(7).repeat()\n",
    "# valdataset = dataset.skip(7).repeat()\n",
    "\n",
    "# def get_test_batch():\n",
    "#         try:\n",
    "#             for batch in tempdataset:\n",
    "#                 print(batch.numpy())\n",
    "#         except StopIteration:\n",
    "#             print(\"End of dataset\")\n",
    "\n",
    "# while True:\n",
    "#       b = get_test_batch()\n",
    "#       print(b)\n",
    "\n",
    "args = {\n",
    "    'data_subset': 'family_x2',\n",
    "}\n",
    "\n",
    "# Training data\n",
    "assert os.path.exists(DATA_DIR + 'disparity/' + args['data_subset'] + '/left/'), \"Improper data_subset selected\"\n",
    "pfm_paths = []\n",
    "pfm_paths.append(DATA_DIR + 'disparity/' + args['data_subset'] + '/left/')\n",
    "pfm_paths.append(DATA_DIR + 'material_index/' + args['data_subset'] + '/left/')\n",
    "pfm_paths.append(DATA_DIR + 'object_index/' + args['data_subset'] + '/left/')\n",
    "pfm_paths.append(DATA_DIR + 'optical_flow/' + args['data_subset'] + '/into_future/left/')\n",
    "pgm_paths = []\n",
    "pgm_paths.append(DATA_DIR + 'motion_boundaries/' + args['data_subset'] + '/into_future/left/')\n",
    "png_paths = []\n",
    "png_paths.append(DATA_DIR + 'frames_cleanpass/' + args['data_subset'] + '/left')\n",
    "num_sources = len(pfm_paths) + len(pgm_paths) + len(png_paths)\n",
    "\n",
    "# Training parameters\n",
    "nt = 10  # number of time steps\n",
    "nb_epoch = 150  # 150\n",
    "batch_size = 4  # 4\n",
    "sequences_per_epoch_train = 10  # 500\n",
    "sequences_per_epoch_val = 1  # 500\n",
    "assert sequences_per_epoch_train is None or type(sequences_per_epoch_train) == int # this will override the default of (dataset size / batch size)\n",
    "assert sequences_per_epoch_val is None or type(sequences_per_epoch_val) == int # this will override the default of (dataset size / batch size)\n",
    "# N_seq_val = 20  # number of sequences to use for validation\n",
    "# num_P_CNN = args[\"num_P_CNN\"]\n",
    "# num_R_CLSTM = args[\"num_R_CLSTM\"]\n",
    "# output_channels = args[\"output_channels\"]\n",
    "original_im_shape = (540, 960, 3)\n",
    "downscale_factor = 4\n",
    "im_shape = (original_im_shape[0] // downscale_factor, original_im_shape[1] // downscale_factor, 3)\n",
    "\n",
    "ts = .7\n",
    "vs = (1 - ts) / 2\n",
    "#  Create and split dataset\n",
    "datasets, length = create_dataset_from_serialized_generator(pfm_paths, pgm_paths, png_paths, output_mode='Error',\n",
    "                                                        im_height=im_shape[0], im_width=im_shape[1],\n",
    "                                                        batch_size=batch_size, nt=nt, reserialize=False, shuffle=True, resize=True)\n",
    "\n",
    "train_size = int(ts * length)\n",
    "val_size = int(vs * length)\n",
    "test_size = int(vs * length)\n",
    "train_dataset, val_dataset, test_dataset = datasets\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Validation size: {val_size}\")\n",
    "print(f\"Test size: {test_size}\")\n",
    "print(\"All datasets created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 38\n",
      "1, 60\n",
      "2, 94\n",
      "3, 2\n",
      "4, 97\n",
      "45.413803\n",
      "5, 87\n",
      "6, 53\n",
      "7, 34\n",
      "8, 23\n",
      "44.777298\n",
      "9, 19\n",
      "10, 83\n",
      "11, 25\n",
      "12, 50\n",
      "45.29929\n",
      "13, 22\n",
      "14, 65\n",
      "15, 90\n",
      "16, 6\n",
      "44.32845\n",
      "17, 41\n",
      "18, 72\n",
      "19, 40\n",
      "20, 80\n",
      "45.02596\n",
      "21, 102\n",
      "22, 69\n",
      "23, 35\n",
      "24, 31\n",
      "44.46981\n",
      "25, 85\n",
      "26, 52\n",
      "27, 45\n",
      "28, 71\n",
      "44.56496\n",
      "29, 100\n",
      "30, 15\n",
      "31, 18\n",
      "32, 28\n",
      "45.49008\n",
      "33, 86\n",
      "34, 95\n",
      "35, 46\n",
      "36, 81\n",
      "44.97999\n",
      "37, 98\n",
      "38, 57\n",
      "39, 0\n",
      "40, 96\n",
      "45.058414\n",
      "41, 3\n",
      "42, 48\n",
      "43, 7\n",
      "44, 63\n",
      "46.048508\n",
      "45, 58\n",
      "46, 47\n",
      "47, 93\n",
      "48, 37\n",
      "44.352093\n",
      "49, 32\n",
      "50, 74\n",
      "51, 5\n",
      "52, 89\n",
      "45.201817\n",
      "53, 88\n",
      "54, 62\n",
      "55, 14\n",
      "56, 91\n",
      "44.039745\n",
      "57, 17\n",
      "58, 42\n",
      "59, 11\n",
      "60, 9\n",
      "45.234756\n",
      "61, 66\n",
      "62, 54\n",
      "63, 30\n",
      "64, 99\n",
      "44.981094\n",
      "65, 61\n",
      "66, 13\n",
      "67, 101\n",
      "68, 64\n",
      "45.6862\n",
      "69, 76\n",
      "70, 55\n",
      "71, 84\n",
      "72, 39\n",
      "43.58017\n",
      "73, 78\n",
      "74, 21\n",
      "75, 56\n",
      "76, 44\n",
      "44.705967\n",
      "77, 73\n",
      "78, 29\n",
      "79, 79\n",
      "80, 20\n",
      "44.3121\n",
      "81, 12\n",
      "82, 27\n",
      "83, 68\n",
      "84, 26\n",
      "45.367134\n",
      "85, 75\n",
      "86, 77\n",
      "87, 33\n",
      "88, 4\n",
      "44.508453\n",
      "89, 105\n",
      "90, 51\n",
      "91, 1\n",
      "92, 82\n",
      "45.722466\n",
      "93, 43\n",
      "94, 103\n",
      "95, 70\n",
      "96, 24\n",
      "44.223816\n",
      "97, 104\n",
      "98, 10\n",
      "99, 67\n",
      "100, 36\n",
      "45.122578\n",
      "101, 92\n",
      "102, 16\n",
      "103, 59\n",
      "104, 8\n",
      "44.902424\n",
      "105, 49\n",
      "0, 75\n",
      "45.623516\n",
      "1, 8\n",
      "2, 95\n",
      "3, 40\n",
      "4, 12\n",
      "45.269917\n",
      "5, 16\n",
      "6, 74\n",
      "7, 87\n",
      "8, 57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m train_dataset:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39;49m(np\u001b[39m.\u001b[39;49mmean(batch[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    811\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    774\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    775\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    776\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    778\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3024\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3023\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3025\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[1;32m   3026\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[1;32m   3027\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9, 7\n",
      "10, 5\n",
      "11, 56\n",
      "12, 59\n",
      "13, 48\n",
      "14, 21\n",
      "15, 39\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "for batch in train_dataset:\n",
    "    print(np.mean(batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 136\n",
      "1, 148\n",
      "2, 145\n",
      "3, 146\n",
      "4, 142\n",
      "46.423634\n",
      "5, 147\n",
      "6, 135\n",
      "7, 143\n",
      "8, 131\n",
      "46.39489\n",
      "9, 138\n",
      "10, 144\n",
      "11, 128\n",
      "12, 141\n",
      "46.144268\n",
      "13, 140\n",
      "14, 133\n",
      "15, 139\n",
      "16, 137\n",
      "46.31312\n",
      "17, 132\n",
      "18, 130\n",
      "19, 134\n",
      "20, 129\n",
      "46.08577\n",
      "21, 149\n",
      "0, 134\n",
      "46.175507\n",
      "1, 142\n",
      "2, 135\n",
      "3, 144\n",
      "4, 133\n",
      "46.308174\n",
      "5, 146\n",
      "6, 138\n",
      "7, 149\n",
      "8, 140\n",
      "46.343872\n",
      "9, 145\n",
      "10, 143\n",
      "11, 129\n",
      "12, 139\n",
      "46.299953\n",
      "13, 136\n",
      "14, 141\n",
      "15, 137\n",
      "16, 130\n",
      "46.324444\n",
      "17, 147\n",
      "18, 131\n",
      "19, 148\n",
      "20, 128\n",
      "46.214428\n",
      "21, 132\n",
      "0, 129\n",
      "45.91709\n",
      "1, 144\n",
      "2, 128\n",
      "3, 146\n",
      "4, 131\n",
      "46.159527\n",
      "5, 137\n",
      "6, 136\n",
      "7, 133\n",
      "8, 145\n",
      "46.138866\n",
      "9, 139\n",
      "10, 141\n",
      "11, 147\n",
      "12, 143\n",
      "46.43889\n",
      "13, 130\n",
      "14, 132\n",
      "15, 148\n",
      "16, 135\n",
      "46.220963\n",
      "17, 138\n",
      "18, 142\n",
      "19, 149\n",
      "20, 140\n",
      "46.360153\n",
      "21, 134\n",
      "0, 136\n",
      "46.26209\n",
      "1, 130\n",
      "2, 128\n",
      "3, 138\n",
      "4, 145\n",
      "46.071068\n",
      "5, 135\n",
      "6, 143\n",
      "7, 144\n",
      "8, 142\n",
      "46.40054\n",
      "9, 137\n",
      "10, 139\n",
      "11, 134\n",
      "12, 149\n",
      "46.304188\n",
      "13, 148\n",
      "14, 146\n",
      "15, 147\n",
      "16, 131\n",
      "46.489254\n",
      "17, 140\n",
      "18, 129\n",
      "19, 133\n",
      "20, 132\n",
      "46.07405\n",
      "21, 141\n",
      "0, 132\n",
      "46.22068\n",
      "1, 133\n",
      "2, 135\n",
      "3, 146\n",
      "4, 130\n",
      "46.191563\n",
      "5, 136\n",
      "6, 144\n",
      "7, 139\n",
      "8, 141\n",
      "46.245453\n",
      "9, 145\n",
      "10, 143\n",
      "11, 149\n",
      "12, 140\n",
      "46.46384\n",
      "13, 138\n",
      "14, 129\n",
      "15, 128\n",
      "16, 131\n",
      "46.098362\n",
      "17, 148\n",
      "18, 137\n",
      "19, 142\n",
      "20, 134\n",
      "46.29517\n",
      "21, 147\n",
      "0, 133\n",
      "46.310078\n",
      "1, 135\n",
      "2, 140\n",
      "3, 145\n",
      "4, 134\n",
      "46.283974\n",
      "5, 143\n",
      "6, 137\n",
      "7, 139\n",
      "8, 141\n",
      "46.308453\n",
      "9, 128\n",
      "10, 144\n",
      "11, 129\n",
      "12, 138\n",
      "46.14312\n",
      "13, 131\n",
      "14, 147\n",
      "15, 136\n",
      "16, 146\n",
      "46.253002\n",
      "17, 130\n",
      "18, 149\n",
      "19, 132\n",
      "20, 148\n",
      "46.227177\n",
      "21, 142\n",
      "0, 129\n",
      "46.467407\n",
      "1, 134\n",
      "2, 147\n",
      "3, 133\n",
      "4, 140\n",
      "46.139378\n",
      "5, 146\n",
      "6, 128\n",
      "7, 141\n",
      "8, 149\n",
      "46.27947\n",
      "9, 139\n",
      "10, 136\n",
      "11, 144\n",
      "12, 130\n",
      "46.38967\n",
      "13, 132\n",
      "14, 137\n",
      "15, 138\n",
      "16, 145\n",
      "46.133995\n",
      "17, 131\n",
      "18, 135\n",
      "19, 142\n",
      "20, 148\n",
      "46.268963\n",
      "21, 143\n",
      "0, 147\n",
      "46.47594\n",
      "1, 149\n",
      "2, 141\n",
      "3, 136\n",
      "4, 133\n",
      "46.40874\n",
      "5, 140\n",
      "6, 148\n",
      "7, 134\n",
      "8, 138\n",
      "46.27253\n",
      "9, 131\n",
      "10, 129\n",
      "11, 143\n",
      "12, 135\n",
      "46.152847\n",
      "13, 145\n",
      "14, 137\n",
      "15, 130\n",
      "16, 128\n",
      "46.214928\n",
      "17, 132\n",
      "18, 144\n",
      "19, 146\n",
      "20, 142\n",
      "46.19897\n",
      "21, 139\n",
      "0, 139\n",
      "46.4028\n",
      "1, 134\n",
      "2, 129\n",
      "3, 148\n",
      "4, 138\n",
      "46.210884\n",
      "5, 143\n",
      "6, 141\n",
      "7, 130\n",
      "8, 142\n",
      "46.279747\n",
      "9, 128\n",
      "10, 146\n",
      "11, 144\n",
      "12, 145\n",
      "46.305218\n",
      "13, 147\n",
      "14, 132\n",
      "15, 133\n",
      "16, 149\n",
      "46.266922\n",
      "17, 135\n",
      "18, 131\n",
      "19, 137\n",
      "20, 136\n",
      "46.229706\n",
      "21, 140\n",
      "0, 136\n",
      "46.313942\n",
      "1, 130\n",
      "2, 145\n",
      "3, 132\n",
      "4, 144\n",
      "46.162163\n",
      "5, 133\n",
      "6, 134\n",
      "7, 137\n",
      "8, 147\n",
      "46.24024\n",
      "9, 149\n",
      "10, 143\n",
      "11, 129\n",
      "12, 128\n",
      "46.325596\n",
      "13, 135\n",
      "14, 131\n",
      "15, 139\n",
      "16, 138\n",
      "46.08113\n",
      "17, 140\n",
      "18, 146\n",
      "19, 148\n",
      "20, 142\n",
      "46.42373\n",
      "21, 141\n",
      "0, 133\n",
      "46.433155\n",
      "1, 138\n",
      "2, 148\n",
      "3, 143\n",
      "4, 140\n",
      "46.33766\n",
      "5, 139\n",
      "6, 135\n",
      "7, 149\n",
      "8, 144\n",
      "9, 129\n",
      "10, 134\n",
      "11, 146\n",
      "12, 145\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# while True:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#     try:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#         batch = next(dit) # take just batch_x not batch_y\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m#         batch = next(dit)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m#     print(np.mean(batch[0][0]))\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dit)    \n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmean(batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    811\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    774\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    775\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    776\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    778\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3024\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3023\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3025\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[1;32m   3026\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[1;32m   3027\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13, 132\n",
      "14, 136\n",
      "15, 128\n",
      "16, 141\n",
      "17, 142\n",
      "18, 137\n",
      "19, 130\n"
     ]
    }
   ],
   "source": [
    "dit = iter(test_dataset)\n",
    "# while True:\n",
    "#     try:\n",
    "#         batch = next(dit) # take just batch_x not batch_y\n",
    "#     except StopIteration:\n",
    "#         print(\"Stopped\")\n",
    "#         dit = iter(test_dataset)\n",
    "#         batch = next(dit)\n",
    "#     print(np.mean(batch[0][0]))\n",
    "while True:\n",
    "    batch = next(dit)    \n",
    "    print(np.mean(batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 127\n",
      "1, 107\n",
      "2, 110\n",
      "3, 112\n",
      "4, 118\n",
      "45.61526\n",
      "5, 120\n",
      "6, 115\n",
      "7, 119\n",
      "8, 124\n",
      "45.641224\n",
      "9, 109\n",
      "10, 111\n",
      "11, 108\n",
      "12, 125\n",
      "45.65186\n",
      "13, 114\n",
      "14, 117\n",
      "15, 113\n",
      "16, 122\n",
      "45.657486\n",
      "17, 121\n",
      "18, 123\n",
      "19, 106\n",
      "20, 126\n",
      "45.499413\n",
      "21, 116\n",
      "0, 107\n",
      "45.689205\n",
      "1, 109\n",
      "2, 112\n",
      "3, 116\n",
      "4, 113\n",
      "45.582085\n",
      "5, 127\n",
      "6, 123\n",
      "7, 124\n",
      "8, 108\n",
      "45.692146\n",
      "9, 111\n",
      "10, 118\n",
      "11, 115\n",
      "12, 125\n",
      "45.64042\n",
      "13, 106\n",
      "14, 126\n",
      "15, 120\n",
      "16, 114\n",
      "45.528275\n",
      "17, 117\n",
      "18, 121\n",
      "19, 110\n",
      "20, 122\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m val_dataset:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39;49m(np\u001b[39m.\u001b[39;49mmean(batch[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    811\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    774\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    775\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    776\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    778\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3024\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3023\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3025\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[1;32m   3026\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[1;32m   3027\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21, 119\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch in val_dataset:\n",
    "    print(np.mean(batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 137\n",
      "1, 138\n",
      "2, 145\n",
      "3, 132\n",
      "4, 141\n",
      "46.276554\n",
      "5, 142\n",
      "6, 140\n",
      "7, 144\n",
      "8, 128\n",
      "46.433605\n",
      "9, 143\n",
      "10, 136\n",
      "11, 149\n",
      "12, 130\n",
      "46.24987\n",
      "13, 135\n",
      "14, 148\n",
      "15, 131\n",
      "16, 139\n",
      "46.137882\n",
      "17, 146\n",
      "18, 133\n",
      "19, 134\n",
      "20, 147\n",
      "46.263626\n",
      "21, 129\n",
      "0, 128\n",
      "46.175797\n",
      "1, 147\n",
      "2, 136\n",
      "3, 141\n",
      "4, 135\n",
      "46.240093\n",
      "5, 130\n",
      "6, 140\n",
      "7, 145\n",
      "8, 139\n",
      "46.243187\n",
      "9, 149\n",
      "10, 132\n",
      "11, 137\n",
      "12, 131\n",
      "46.287685\n",
      "13, 143\n",
      "14, 133\n",
      "15, 142\n",
      "16, 134\n",
      "46.236645\n",
      "17, 144\n",
      "18, 148\n",
      "19, 146\n",
      "20, 138\n",
      "46.39559\n",
      "21, 129\n",
      "0, 134\n",
      "46.092434\n",
      "1, 139\n",
      "2, 130\n",
      "3, 131\n",
      "4, 148\n",
      "46.092224\n",
      "5, 140\n",
      "6, 129\n",
      "7, 146\n",
      "8, 142\n",
      "46.30836\n",
      "9, 128\n",
      "10, 137\n",
      "11, 135\n",
      "12, 132\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m test_dataset:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39;49m(np\u001b[39m.\u001b[39;49mmean(batch[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    811\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    774\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    775\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    776\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    778\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3024\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3023\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3025\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIteratorGetNext\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, iterator, \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types,\n\u001b[1;32m   3026\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes)\n\u001b[1;32m   3027\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13, 145\n",
      "14, 149\n",
      "15, 136\n",
      "16, 144\n",
      "17, 138\n",
      "18, 133\n",
      "19, 143\n"
     ]
    }
   ],
   "source": [
    "for batch in test_dataset:\n",
    "    print(np.mean(batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_batch(dataset):\n",
    "        try:\n",
    "            for batch in dataset:\n",
    "                print(np.mean(batch[0][0]))\n",
    "        except StopIteration:\n",
    "            print(\"End of dataset\")\n",
    "\n",
    "def get_test_batch2(dataset):\n",
    "        dit = iter(dataset)\n",
    "        try:\n",
    "            batch = next(dit)\n",
    "            print(np.mean(batch[0][0]))\n",
    "        except StopIteration:\n",
    "            print(\"End of dataset\")\n",
    "            dit = iter(dataset)\n",
    "            batch = next(dit)\n",
    "            print(np.mean(batch[0][0]))\n",
    "\n",
    "while True:\n",
    "      get_test_batch2(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 23:00:14.254803: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-16 23:00:14.254834: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-16 23:00:14.255845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-16 23:00:14.261428: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-16 23:00:15.107546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evalexii/miniconda3/envs/PPN/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras_cv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 16)\n",
      "(1, 3, 3, 16)\n"
     ]
    }
   ],
   "source": [
    "input = tf.ones((1, 5, 5, 16), dtype=tf.float32)\n",
    "x = keras.layers.Conv2D(16, (3, 3))(input)\n",
    "print(x.shape)\n",
    "output = keras_cv.layers.SqueezeAndExcite2D(x.shape[-1])(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:GPU:0}} Outer dimensions of indices and update must match. Indices shape: [1,1,1,1], updates shape:[2,5,5,1] [Op:TensorScatterUpdate] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     index \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([[[[channel]]]])  \u001b[39m# Note the four brackets for the index to match the tensor's 4D shape\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     update \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mzeros(single_channel_shape, dtype\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m---> 18\u001b[0m     channel_mask \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mtensor_scatter_nd_update(channel_mask, index, update)\n\u001b[1;32m     20\u001b[0m \u001b[39m# Multiply the original tensor by the mask\u001b[39;00m\n\u001b[1;32m     21\u001b[0m result \u001b[39m=\u001b[39m x \u001b[39m*\u001b[39m channel_mask\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/PPN/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:GPU:0}} Outer dimensions of indices and update must match. Indices shape: [1,1,1,1], updates shape:[2,5,5,1] [Op:TensorScatterUpdate] name: "
     ]
    }
   ],
   "source": [
    "# Example tensor x with shape [batch, height, width, channels]\n",
    "# Example: tf.random.normal([2, 5, 5, 3]) generates a tensor with 2 batches, 5x5 spatial dimensions, and 3 channels\n",
    "\n",
    "shape = [2, 5, 5, 3]\n",
    "single_channel_shape = shape[:-1] + [1]\n",
    "x = tf.random.normal(shape)\n",
    "\n",
    "# List of channels to set to zero (0-indexed)\n",
    "channels_to_zero = [0, 2]  # Set channel 0 and channel 2 to zero\n",
    "\n",
    "# Create a mask where selected channels are zero and others are one\n",
    "channel_mask = tf.ones_like(x)\n",
    "for channel in channels_to_zero:\n",
    "    # Using tf.tensor_scatter_nd_update to set specific channels to zero in the mask\n",
    "    index = tf.constant([[[[channel]]]])  # Note the four brackets for the index to match the tensor's 4D shape\n",
    "\n",
    "    update = tf.zeros(single_channel_shape, dtype=x.dtype)\n",
    "    channel_mask = tf.tensor_scatter_nd_update(channel_mask, index, update)\n",
    "\n",
    "# Multiply the original tensor by the mask\n",
    "result = x * channel_mask\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-1.4892974  -1.5584548  -0.40928242 -0.9602487   0.3120145 ]\n",
      "  [ 1.0133559  -0.31203923 -0.19552547  0.53889555 -1.0778242 ]\n",
      "  [-1.2669659   0.9875662  -1.7057128  -1.5694541  -0.8509229 ]\n",
      "  [-0.7506281  -0.6145227   0.7555143   0.07049035  0.6204936 ]\n",
      "  [-0.96874434 -0.53032476  0.02862556 -0.48450115 -0.4646648 ]]\n",
      "\n",
      " [[ 0.6145058  -0.14068246  0.6534147  -1.3314594  -1.580457  ]\n",
      "  [-0.89542186  0.4455467   0.84875476 -0.58786786 -2.1768298 ]\n",
      "  [ 0.22862211  1.0475172   0.7032318  -0.92729384  1.9831867 ]\n",
      "  [ 1.4115286   1.2384869  -0.05710787 -1.1609427  -1.0961728 ]\n",
      "  [-1.4623992   1.22778     2.1681988   0.22070688  0.8555502 ]]], shape=(2, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# Example tensor x with shape [batch, height, width, channels]\n",
    "x = tf.random.normal([2, 5, 5, 4])  # Assume tensor with 4 channels\n",
    "\n",
    "# List of channel indices to set to zero\n",
    "channels_to_zero = [0, 1, 3]  # Zero out channels 0, 1, and 3\n",
    "\n",
    "# Create a mask for the channels\n",
    "mask = tf.constant([i not in channels_to_zero for i in range(x.shape[-1])], dtype=tf.float32)\n",
    "\n",
    "# Reshape mask to be broadcastable across the batch and spatial dimensions\n",
    "mask = tf.reshape(mask, [1, 1, 1, x.shape[-1]])\n",
    "\n",
    "# Apply the mask to the tensor\n",
    "x = x * mask\n",
    "\n",
    "print(x[..., 2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PPN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
